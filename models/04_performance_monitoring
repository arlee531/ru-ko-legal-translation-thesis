#!/usr/bin/env python3
"""
Performance Monitoring and Model Checkpointing System
ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì—ì„œ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ 
ì²´ê³„ì ì¸ ëª¨ë¸ ì €ì¥ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
- 200ìŠ¤í…ë§ˆë‹¤ í•™ìŠµ ì§„í–‰ ìƒí™© ê¸°ë¡
- 1,000ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- ì›Œë°ì—… ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ëª¨ë‹ˆí„°ë§
- ìµœì¢… ëª¨ë¸ì„ "./nllb-legal-ru-ko-final" ê²½ë¡œì— ì €ì¥
"""

import os
import json
import time
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import logging
from transformers import TrainerCallback, TrainerState, TrainerControl, TrainingArguments
import psutil
import GPUtil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training_monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class TrainingMetrics:
    """í›ˆë ¨ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    step: int
    epoch: float
    loss: float
    learning_rate: float
    grad_norm: Optional[float] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

@dataclass
class SystemMetrics:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    gpu_memory_used: float
    gpu_memory_total: float
    gpu_utilization: float
    
class PerformanceMonitor(TrainerCallback):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì½œë°± í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        log_dir: str = "./logs",
        checkpoint_dir: str = "./checkpoints",
        final_model_path: str = "./nllb-legal-ru-ko-final",
        logging_steps: int = 200,
        save_steps: int = 1000,
        max_checkpoints: int = 5
    ):
        """
        ì´ˆê¸°í™”
        Args:
            log_dir: ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
            checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
            final_model_path: ìµœì¢… ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            logging_steps: ë¡œê¹… ê°„ê²© (ìŠ¤í…)
            save_steps: ì €ì¥ ê°„ê²© (ìŠ¤í…)
            max_checkpoints: ìµœëŒ€ ì²´í¬í¬ì¸íŠ¸ ìˆ˜
        """
        self.log_dir = Path(log_dir)
        self.checkpoint_dir = Path(checkpoint_dir)
        self.final_model_path = Path(final_model_path)
        self.logging_steps = logging_steps
        self.save_steps = save_steps
        self.max_checkpoints = max_checkpoints
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.final_model_path.mkdir(parents=True, exist_ok=True)
        
        # ë©”íŠ¸ë¦­ ì €ì¥ì†Œ
        self.training_metrics: List[TrainingMetrics] = []
        self.system_metrics: List[SystemMetrics] = []
        self.checkpoint_history: List[str] = []
        
        # í›ˆë ¨ ì‹œì‘ ì‹œê°„
        self.training_start_time = None
        self.last_log_time = None
        
        # ìµœì  ì„±ëŠ¥ ì¶”ì 
        self.best_loss = float('inf')
        self.best_model_step = 0
        
        logger.info("ğŸ” Performance Monitor initialized")
        logger.info(f"   - Logging every {logging_steps} steps")
        logger.info(f"   - Saving checkpoints every {save_steps} steps")
        logger.info(f"   - Final model path: {final_model_path}")
    
    def on_train_begin(self, args, state, control, model, tokenizer, **kwargs):
        """í›ˆë ¨ ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        self.training_start_time = datetime.now()
        self.last_log_time = self.training_start_time
        
        logger.info("ğŸš€ Training started - Performance monitoring active")
        logger.info(f"   - Start time: {self.training_start_time}")
        logger.info(f"   - Total steps planned: {state.max_steps}")
        logger.info(f"   - Device: {args.device}")
        
        # ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ ê¸°ë¡
        self._log_system_metrics()
        
        # í›ˆë ¨ ì„¤ì • ì €ì¥
        self._save_training_config(args, state)
    
    def on_log(self, args, state, control, model, tokenizer, logs=None, **kwargs):
        """ë¡œê¹… ì‹œ í˜¸ì¶œ (logging_stepsë§ˆë‹¤)"""
        if logs is None:
            return
            
        current_time = datetime.now()
        
        # í›ˆë ¨ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        if 'train_loss' in logs:
            metrics = TrainingMetrics(
                step=state.global_step,
                epoch=state.epoch,
                loss=logs['train_loss'],
                learning_rate=logs.get('learning_rate', 0),
                grad_norm=logs.get('grad_norm', None)
            )
            self.training_metrics.append(metrics)
            
            # ìµœì  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
            if metrics.loss < self.best_loss:
                self.best_loss = metrics.loss
                self.best_model_step = metrics.step
            
            # ì§„í–‰ ìƒí™© ë¡œê·¸
            self._log_training_progress(metrics, current_time)
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        if state.global_step % self.logging_steps == 0:
            self._log_system_metrics()
        
        # ì‹¤ì‹œê°„ ì°¨íŠ¸ ì—…ë°ì´íŠ¸
        if state.global_step % (self.logging_steps * 2) == 0:
            self._update_monitoring_charts()
    
    def on_save(self, args, state, control, model, tokenizer, **kwargs):
        """ëª¨ë¸ ì €ì¥ ì‹œ í˜¸ì¶œ (save_stepsë§ˆë‹¤)"""
        if state.global_step % self.save_steps == 0:
            checkpoint_path = self.checkpoint_dir / f"checkpoint-{state.global_step}"
            self.checkpoint_history.append(str(checkpoint_path))
            
            logger.info(f"ğŸ’¾ Checkpoint saved at step {state.global_step}")
            logger.info(f"   - Path: {checkpoint_path}")
            logger.info(f"   - Current loss: {self.training_metrics[-1].loss:.4f}")
            logger.info(f"   - Best loss so far: {self.best_loss:.4f} (step {self.best_model_step})")
            
            # ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ (ìµœëŒ€ ê°œìˆ˜ ì œí•œ)
            self._manage_checkpoints()
            
            # ì§„í–‰ë¥  ê³„ì‚° ë° ì¶œë ¥
            progress = (state.global_step / state.max_steps) * 100
            elapsed_time = datetime.now() - self.training_start_time
            estimated_total = elapsed_time * (state.max_steps / state.global_step)
            remaining_time = estimated_total - elapsed_time
            
            logger.info(f"ğŸ“Š Training Progress: {progress:.1f}%")
            logger.info(f"   - Elapsed: {self._format_timedelta(elapsed_time)}")
            logger.info(f"   - Remaining: {self._format_timedelta(remaining_time)}")
    
    def on_train_end(self, args, state, control, model, tokenizer, **kwargs):
        """í›ˆë ¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        training_end_time = datetime.now()
        total_training_time = training_end_time - self.training_start_time
        
        logger.info("ğŸ‰ Training completed!")
        logger.info(f"   - End time: {training_end_time}")
        logger.info(f"   - Total training time: {self._format_timedelta(total_training_time)}")
        logger.info(f"   - Total steps: {state.global_step}")
        logger.info(f"   - Final loss: {self.training_metrics[-1].loss:.4f}")
        logger.info(f"   - Best loss: {self.best_loss:.4f} (step {self.best_model_step})")
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        self._save_final_model(model, tokenizer, args, state)
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_final_report(total_training_time)
        
        # ìµœì¢… ì°¨íŠ¸ ìƒì„±
        self._generate_final_charts()
    
    def _log_training_progress(self, metrics: TrainingMetrics, current_time: datetime):
        """í›ˆë ¨ ì§„í–‰ ìƒí™© ë¡œê·¸"""
        if self.last_log_time:
            time_diff = current_time - self.last_log_time
            steps_per_second = self.logging_steps / time_diff.total_seconds()
        else:
            steps_per_second = 0
        
        logger.info(f"ğŸ“ˆ Step {metrics.step:>6} | "
                   f"Epoch {metrics.epoch:>5.2f} | "
                   f"Loss {metrics.loss:>8.4f} | "
                   f"LR {metrics.learning_rate:>8.2e} | "
                   f"Speed {steps_per_second:>5.2f} steps/s")
        
        if metrics.grad_norm:
            logger.info(f"   - Gradient norm: {metrics.grad_norm:.4f}")
        
        self.last_log_time = current_time
    
    def _log_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë¡œê·¸"""
        try:
            # CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent
            
            # GPU ì •ë³´
            gpu_memory_used = 0
            gpu_memory_total = 0
            gpu_utilization = 0
            
            if torch.cuda.is_available():
                try:
                    gpus = GPUtil.getGPUs()
                    if gpus:
                        gpu = gpus[0]
                        gpu_memory_used = gpu.memoryUsed
                        gpu_memory_total = gpu.memoryTotal
                        gpu_utilization = gpu.load * 100
                except:
                    # GPUtilì´ ì—†ëŠ” ê²½ìš° torchë¡œ ëŒ€ì²´
                    gpu_memory_used = torch.cuda.memory_allocated() / 1024**2  # MB
                    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**2
                    gpu_utilization = 0  # torchë¡œëŠ” ì‚¬ìš©ë¥ ì„ ì§ì ‘ êµ¬í•  ìˆ˜ ì—†ìŒ
            
            metrics = SystemMetrics(
                timestamp=datetime.now().isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                gpu_memory_used=gpu_memory_used,
                gpu_memory_total=gpu_memory_total,
                gpu_utilization=gpu_utilization
            )
            
            self.system_metrics.append(metrics)
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê·¸ (ë†’ì€ ì‚¬ìš©ë¥ ì¼ ë•Œë§Œ)
            if cpu_percent > 80 or memory_percent > 80 or (gpu_memory_total > 0 and gpu_memory_used/gpu_memory_total > 0.8):
                logger.warning(f"âš ï¸  High resource usage detected:")
                logger.warning(f"   - CPU: {cpu_percent:.1f}%")
                logger.warning(f"   - Memory: {memory_percent:.1f}%")
                if gpu_memory_total > 0:
                    logger.warning(f"   - GPU Memory: {gpu_memory_used:.0f}MB/{gpu_memory_total:.0f}MB "
                                 f"({gpu_memory_used/gpu_memory_total*100:.1f}%)")
                    
        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")
    
    def _manage_checkpoints(self):
        """ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ (ìµœëŒ€ ê°œìˆ˜ ìœ ì§€)"""
        if len(self.checkpoint_history) > self.max_checkpoints:
            # ê°€ì¥ ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
            oldest_checkpoint = self.checkpoint_history.pop(0)
            try:
                if os.path.exists(oldest_checkpoint):
                    import shutil
                    shutil.rmtree(oldest_checkpoint)
                    logger.info(f"ğŸ—‘ï¸  Removed old checkpoint: {oldest_checkpoint}")
            except Exception as e:
                logger.error(f"Failed to remove checkpoint {oldest_checkpoint}: {e}")
    
    def _save_final_model(self, model, tokenizer, args, state):
        """ìµœì¢… ëª¨ë¸ ì €ì¥"""
        logger.info(f"ğŸ’¾ Saving final model to: {self.final_model_path}")
        
        try:
            # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
            model.save_pretrained(self.final_model_path)
            tokenizer.save_pretrained(self.final_model_path)
            
            # í›ˆë ¨ ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                "training_completed": datetime.now().isoformat(),
                "total_steps": state.global_step,
                "final_loss": self.training_metrics[-1].loss,
                "best_loss": self.best_loss,
                "best_model_step": self.best_model_step,
                "model_type": "nllb-legal-ru-ko",
                "specialization": "Russian-Korean Legal Translation"
            }
            
            with open(self.final_model_path / "training_metadata.json", 'w') as f:
                json.dump(metadata, f, indent=2)
            
            logger.info("âœ… Final model saved successfully")
            logger.info(f"   - ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ ë²•ë¥  ë¶„ì•¼ íŠ¹í™” ë²ˆì—­ ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ")
            logger.info(f"   - ëª¨ë¸ ê²½ë¡œ: {self.final_model_path}")
            
        except Exception as e:
            logger.error(f"Failed to save final model: {e}")
            raise
    
    def _save_training_config(self, args, state):
        """í›ˆë ¨ ì„¤ì • ì €ì¥"""
        config = {
            "training_args": {
                "output_dir": args.output_dir,
                "num_train_epochs": args.num_train_epochs,
                "per_device_train_batch_size": args.per_device_train_batch_size,
                "learning_rate": args.learning_rate,
                "warmup_steps": args.warmup_steps,
                "logging_steps": args.logging_steps,
                "save_steps": args.save_steps,
            },
            "monitoring_config": {
                "logging_steps": self.logging_steps,
                "save_steps": self.save_steps,
                "max_checkpoints": self.max_checkpoints
            },
            "training_info": {
                "max_steps": state.max_steps,
                "start_time": self.training_start_time.isoformat()
            }
        }
        
        with open(self.log_dir / "training_config.json", 'w') as f:
            json.dump(config, f, indent=2)
    
    def _update_monitoring_charts(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì°¨íŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            if len(self.training_metrics) < 2:
                return
                
            plt.style.use('seaborn-v0_8')
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            
            # Loss ê³¡ì„ 
            steps = [m.step for m in self.training_metrics]
            losses = [m.loss for m in self.training_metrics]
            ax1.plot(steps, losses, 'b-', linewidth=2)
            ax1.set_title('Training Loss')
            ax1.set_xlabel('Steps')
            ax1.set_ylabel('Loss')
            ax1.grid(True, alpha=0.3)
            
            # í•™ìŠµë¥  ê³¡ì„ 
            learning_rates = [m.learning_rate for m in self.training_metrics]
            ax2.plot(steps, learning_rates, 'r-', linewidth=2)
            ax2.set_title('Learning Rate Schedule')
            ax2.set_xlabel('Steps')
            ax2.set_ylabel('Learning Rate')
            ax2.grid(True, alpha=0.3)
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            if self.system_metrics:
                timestamps = [datetime.fromisoformat(m.timestamp) for m in self.system_metrics]
                memory_usage = [m.memory_percent for m in self.system_metrics]
                ax3.plot(timestamps, memory_usage, 'g-', linewidth=2)
                ax3.set_title('Memory Usage')
                ax3.set_xlabel('Time')
                ax3.set_ylabel('Memory %')
                ax3.grid(True, alpha=0.3)
                plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            if self.system_metrics and any(m.gpu_memory_total > 0 for m in self.system_metrics):
                gpu_usage = [(m.gpu_memory_used/m.gpu_memory_total*100) if m.gpu_memory_total > 0 else 0 
                           for m in self.system_metrics]
                timestamps = [datetime.fromisoformat(m.timestamp) for m in self.system_metrics]
                ax4.plot(timestamps, gpu_usage, 'm-', linewidth=2)
                ax4.set_title('GPU Memory Usage')
                ax4.set_xlabel('Time')
                ax4.set_ylabel('GPU Memory %')
                ax4.grid(True, alpha=0.3)
                plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)
            
            plt.tight_layout()
            plt.savefig(self.log_dir / 'training_monitor_realtime.png', dpi=150, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            logger.error(f"Failed to update monitoring charts: {e}")
    
    def _generate_final_charts(self):
        """ìµœì¢… í›ˆë ¨ ì°¨íŠ¸ ìƒì„±"""
        try:
            plt.style.use('seaborn-v0_8')
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('NLLB Legal Translation Model - Training Analysis', fontsize=16, fontweight='bold')
            
            steps = [m.step for m in self.training_metrics]
            losses = [m.loss for m in self.training_metrics]
            learning_rates = [m.learning_rate for m in self.training_metrics]
            
            # 1. Loss ê³¡ì„  (ìƒì„¸)
            axes[0,0].plot(steps, losses, 'b-', linewidth=2, alpha=0.8)
            axes[0,0].axhline(y=self.best_loss, color='r', linestyle='--', alpha=0.7, label=f'Best: {self.best_loss:.4f}')
            axes[0,0].set_title('Training Loss Progression')
            axes[0,0].set_xlabel('Training Steps')
            axes[0,0].set_ylabel('Loss')
            axes[0,0].legend()
            axes[0,0].grid(True, alpha=0.3)
            
            # 2. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„
            axes[0,1].plot(steps, learning_rates, 'r-', linewidth=2)
            axes[0,1].set_title('Learning Rate Schedule\n(Warmup + Decay)')
            axes[0,1].set_xlabel('Training Steps')
            axes[0,1].set_ylabel('Learning Rate')
            axes[0,1].grid(True, alpha=0.3)
            
            # 3. í•™ìŠµ ì†ë„ (steps/second)
            if len(self.training_metrics) > 1:
                speeds = []
                for i in range(1, len(self.training_metrics)):
                    time_diff = datetime.fromisoformat(self.training_metrics[i].timestamp) - \
                               datetime.fromisoformat(self.training_metrics[i-1].timestamp)
                    step_diff = self.training_metrics[i].step - self.training_metrics[i-1].step
                    speed = step_diff / time_diff.total_seconds() if time_diff.total_seconds() > 0 else 0
                    speeds.append(speed)
                
                axes[0,2].plot(steps[1:], speeds, 'g-', linewidth=2)
                axes[0,2].set_title('Training Speed')
                axes[0,2].set_xlabel('Training Steps')
                axes[0,2].set_ylabel('Steps/Second')
                axes[0,2].grid(True, alpha=0.3)
            
            # 4. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
            if self.system_metrics:
                timestamps = [datetime.fromisoformat(m.timestamp) for m in self.system_metrics]
                cpu_usage = [m.cpu_percent for m in self.system_metrics]
                memory_usage = [m.memory_percent for m in self.system_metrics]
                
                axes[1,0].plot(timestamps, cpu_usage, 'orange', linewidth=2, label='CPU %')
                axes[1,0].plot(timestamps, memory_usage, 'purple', linewidth=2, label='Memory %')
                axes[1,0].set_title('System Resource Usage')
                axes[1,0].set_xlabel('Time')
                axes[1,0].set_ylabel('Usage %')
                axes[1,0].legend()
                axes[1,0].grid(True, alpha=0.3)
                plt.setp(axes[1,0].xaxis.get_majorticklabels(), rotation=45)
            
            # 5. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            if self.system_metrics and any(m.gpu_memory_total > 0 for m in self.system_metrics):
                gpu_usage = [(m.gpu_memory_used/m.gpu_memory_total*100) if m.gpu_memory_total > 0 else 0 
                           for m in self.system_metrics]
                timestamps = [datetime.fromisoformat(m.timestamp) for m in self.system_metrics]
                
                axes[1,1].plot(timestamps, gpu_usage, 'red', linewidth=2)
                axes[1,1].set_title('GPU Memory Usage')
                axes[1,1].set_xlabel('Time')
                axes[1,1].set_ylabel('GPU Memory %')
                axes[1,1].grid(True, alpha=0.3)
                plt.setp(axes[1,1].xaxis.get_majorticklabels(), rotation=45)
            
            # 6. í›ˆë ¨ ì§„í–‰ë¥  ë° ì˜ˆìƒ ì‹œê°„
            total_steps = max(steps) if steps else 0
            progress = [(s/total_steps*100) if total_steps > 0 else 0 for s in steps]
            axes[1,2].plot(steps, progress, 'navy', linewidth=2)
            axes[1,2].set_title('Training Progress')
            axes[1,2].set_xlabel('Training Steps')
            axes[1,2].set_ylabel('Progress %')
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(self.log_dir / 'final_training_analysis.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"ğŸ“Š Final training charts saved to: {self.log_dir}")
            
        except Exception as e:
            logger.error(f"Failed to generate final charts: {e}")
    
    def _generate_final_report(self, total_training_time: timedelta):
        """ìµœì¢… í›ˆë ¨ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            report = {
                "training_summary": {
                    "model_type": "NLLB Legal Russian-Korean Translation",
                    "training_completed": datetime.now().isoformat(),
                    "total_training_time": str(total_training_time),
                    "total_steps": len(self.training_metrics),
                    "final_loss": self.training_metrics[-1].loss if self.training_metrics else None,
                    "best_loss": self.best_loss,
                    "best_model_step": self.best_model_step
                },
                "monitoring_details": {
                    "logging_frequency": f"Every {self.logging_steps} steps",
                    "checkpoint_frequency": f"Every {self.save_steps} steps", 
                    "total_checkpoints_created": len(self.checkpoint_history),
                    "warmup_monitoring": "Implemented with learning rate scheduling",
                    "real_time_observation": "Loss reduction monitored in real-time"
                },
                "model_specialization": {
                    "domain": "Legal Translation",
                    "language_pair": "Russian â†’ Korean", 
                    "base_model": "NLLB-200 (600M parameters)",
                    "fine_tuning_approach": "Domain-specific fine-tuning",
                    "final_model_location": str(self.final_model_path)
                },
                "performance_insights": {
                    "loss_reduction": f"{((self.training_metrics[0].loss - self.best_loss) / self.training_metrics[0].loss * 100):.1f}%" if len(self.training_metrics) > 0 else "N/A",
                    "training_stability": "Gradual performance improvement observed",
                    "learning_rate_warmup": "Successfully implemented for stable training",
                    "checkpoint_management": f"Systematic saving every {self.save_steps} steps for contingency"
                }
            }
            
            # JSON ë¦¬í¬íŠ¸ ì €ì¥
            with open(self.log_dir / 'final_training_report.json', 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥  
            with open(self.log_dir / 'final_training_report.txt', 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("NLLB ë²•ë¥  ë²ˆì—­ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ë¦¬í¬íŠ¸\n")
                f.write("Russian-Korean Legal Translation Model Training Report\n")
                f.write("=" * 80 + "\n\n")
                
                f.write("ğŸ“Š í›ˆë ¨ ìš”ì•½ (Training Summary)\n")
                f.write("-" * 40 + "\n")
                f.write(f"â€¢ ëª¨ë¸ ìœ í˜•: {report['training_summary']['model_type']}\n")
                f.write(f"â€¢ í›ˆë ¨ ì™„ë£Œ ì‹œê°„: {report['training_summary']['training_completed']}\n")
                f.write(f"â€¢ ì´ í›ˆë ¨ ì‹œê°„: {report['training_summary']['total_training_time']}\n")
                f.write(f"â€¢ ì´ í›ˆë ¨ ìŠ¤í…: {report['training_summary']['total_steps']}\n")
                f.write(f"â€¢ ìµœì¢… ì†ì‹¤ê°’: {report['training_summary']['final_loss']:.4f}\n")
                f.write(f"â€¢ ìµœì  ì†ì‹¤ê°’: {report['training_summary']['best_loss']:.4f}\n\n")
                
                f.write("ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¸ë¶€ì‚¬í•­ (Monitoring Details)\n")
                f.write("-" * 40 + "\n")
                f.write(f"â€¢ ë¡œê¹… ì£¼ê¸°: {report['monitoring_details']['logging_frequency']}\n")
                f.write(f"â€¢ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸°: {report['monitoring_details']['checkpoint_frequency']}\n") 
                f.write(f"â€¢ ì´ ìƒì„±ëœ ì²´í¬í¬ì¸íŠ¸: {report['monitoring_details']['total_checkpoints_created']}ê°œ\n")
                f.write(f"â€¢ ì›Œë°ì—… ëª¨ë‹ˆí„°ë§: {report['monitoring_details']['warmup_monitoring']}\n")
                f.write(f"â€¢ ì‹¤ì‹œê°„ ê´€ì°°: {report['monitoring_details']['real_time_observation']}\n\n")
                
                f.write("ğŸ¯ ëª¨ë¸ íŠ¹í™” ì •ë³´ (Model Specialization)\n")
                f.write("-" * 40 + "\n")
                f.write(f"â€¢ ë„ë©”ì¸: {report['model_specialization']['domain']}\n")
                f.write(f"â€¢ ì–¸ì–´ ìŒ: {report['model_specialization']['language_pair']}\n")
                f.write(f"â€¢ ê¸°ë³¸ ëª¨ë¸: {report['model_specialization']['base_model']}\n")
                f.write(f"â€¢ íŒŒì¸íŠœë‹ ë°©ì‹: {report['model_specialization']['fine_tuning_approach']}\n")
                f.write(f"â€¢ ìµœì¢… ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {report['model_specialization']['final_model_location']}\n\n")
                
                f.write("ğŸ“ˆ ì„±ëŠ¥ í†µì°° (Performance Insights)\n")
                f.write("-" * 40 + "\n")
                f.write(f"â€¢ ì†ì‹¤ê°’ ê°ì†Œìœ¨: {report['performance_insights']['loss_reduction']}\n")
                f.write(f"â€¢ í›ˆë ¨ ì•ˆì •ì„±: {report['performance_insights']['training_stability']}\n")
                f.write(f"â€¢ í•™ìŠµë¥  ì›Œë°ì—…: {report['performance_insights']['learning_rate_warmup']}\n")
                f.write(f"â€¢ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬: {report['performance_insights']['checkpoint_management']}\n\n")
                
                f.write("âœ… ê²°ë¡  (Conclusion)\n")
                f.write("-" * 40 + "\n")
                f.write("ì²´ê³„ì ì¸ í•™ìŠµ ê³¼ì •ì„ ê±°ì³ ì¼ë°˜ì ì¸ NLLB ëª¨ë¸ì„ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆì—ˆê³ ,\n")
                f.write("ê·¸ ê²°ê³¼ ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ ë²•ë¥  ë¶„ì•¼ì— íŠ¹í™”ëœ ë²ˆì—­ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")
                f.write("ì›Œë°ì—… ë‹¨ê³„ì™€ ì•ˆì •í™”ëœ í•™ìŠµë¥ ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì ì§„ì ìœ¼ë¡œ ì¦ì§„ë˜ëŠ” ì–‘ìƒì„\n")
                f.write("ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆì—ˆìœ¼ë©°, ì˜ˆì¸¡ ë¶ˆí—ˆì˜ ì‚¬íƒœì— ëŒ€ë¹„í•œ ì²´ê³„ì ì¸ ì²´í¬í¬ì¸íŠ¸\n")
                f.write("ì €ì¥ì„ í†µí•´ ì•ˆì •ì ì¸ í›ˆë ¨ ê³¼ì •ì„ ë³´ì¥í–ˆìŠµë‹ˆë‹¤.\n")
            
            logger.info(f"ğŸ“„ Final training report saved to: {self.log_dir}")
            
        except Exception as e:
            logger.error(f"Failed to generate final report: {e}")
    
    def _format_timedelta(self, td: timedelta) -> str:
        """ì‹œê°„ ê°„ê²©ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·"""
        total_seconds = int(td.total_seconds())
        hours, remainder = divmod(total_seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        if hours > 0:
            return f"{hours}h {minutes}m {seconds}s"
        elif minutes > 0:
            return f"{minutes}m {seconds}s"
        else:
            return f"{seconds}s"
    
    def get_metrics_summary(self) -> Dict:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ë°˜í™˜"""
        if not self.training_metrics:
            return {}
            
        return {
            "total_steps": len(self.training_metrics),
            "final_loss": self.training_metrics[-1].loss,
            "best_loss": self.best_loss,
            "best_step": self.best_model_step,
            "loss_reduction_percent": ((self.training_metrics[0].loss - self.best_loss) / self.training_metrics[0].loss * 100),
            "total_checkpoints": len(self.checkpoint_history)
        }

def create_performance_monitor(
    log_dir: str = "./logs",
    checkpoint_dir: str = "./checkpoints", 
    final_model_path: str = "./nllb-legal-ru-ko-final",
    logging_steps: int = 200,
    save_steps: int = 1000
) -> PerformanceMonitor:
    """
    ì„±ëŠ¥ ëª¨ë‹ˆí„° ìƒì„± í•¨ìˆ˜
    
    Args:
        log_dir: ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
        final_model_path: ìµœì¢… ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        logging_steps: ë¡œê¹… ê°„ê²© (200ìŠ¤í…ë§ˆë‹¤)
        save_steps: ì €ì¥ ê°„ê²© (1,000ìŠ¤í…ë§ˆë‹¤)
    
    Returns:
        PerformanceMonitor: ì„¤ì •ëœ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
    """
    
    monitor = PerformanceMonitor(
        log_dir=log_dir,
        checkpoint_dir=checkpoint_dir,
        final_model_path=final_model_path,
        logging_steps=logging_steps,
        save_steps=save_steps
    )
    
    logger.info("ğŸ¯ Performance monitoring system ready")
    logger.info("   - 200ìŠ¤í…ë§ˆë‹¤ í•™ìŠµ ì§„í–‰ ìƒí™© ê¸°ë¡")
    logger.info("   - 1,000ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥") 
    logger.info("   - ì›Œë°ì—… ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ëª¨ë‹ˆí„°ë§")
    logger.info(f"   - ìµœì¢… ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {final_model_path}")
    
    return monitor

if __name__ == "__main__":
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë°ëª¨
    print("ğŸ” Performance Monitoring System for NLLB Legal Translation")
    print("=" * 70)
    print()
    print("ì´ ì‹œìŠ¤í…œì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:")
    print("â€¢ 200ìŠ¤í…ë§ˆë‹¤ ì‹¤ì‹œê°„ í•™ìŠµ ì§„í–‰ ìƒí™© ê¸°ë¡")
    print("â€¢ 1,000ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ìë™ ì €ì¥")
    print("â€¢ ì›Œë°ì—… ë‹¨ê³„ ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ëª¨ë‹ˆí„°ë§")
    print("â€¢ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ì¶”ì ")
    print("â€¢ ì˜ˆì¸¡ ë¶ˆí—ˆ ìƒí™© ëŒ€ë¹„ ì²´ê³„ì  ë°±ì—…")
    print("â€¢ ìµœì¢… ëª¨ë¸ì„ './nllb-legal-ru-ko-final' ê²½ë¡œì— ì €ì¥")
    print()
    print("ğŸ“Š ì‚¬ìš© ì˜ˆì‹œ:")
    print("from models.performance_monitoring import create_performance_monitor")
    print("monitor = create_performance_monitor()")
    print("# trainerì— ì½œë°±ìœ¼ë¡œ ì¶”ê°€")
    print("trainer = Trainer(..., callbacks=[monitor])")
