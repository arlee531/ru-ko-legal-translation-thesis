{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPOuJfUVgpjj7bR70luNzEV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"643817c7567b49ada66b7b5e3b21602c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6382445c84874b3cb2b5180d2d983f36","IPY_MODEL_f6c842a395524212bb9e920effa69c3f","IPY_MODEL_a7eba23c45c54572be5a1767481d7b01"],"layout":"IPY_MODEL_1a31b8f091a14d58be9ea10fc5a28d37"}},"6382445c84874b3cb2b5180d2d983f36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ede946377dd4471a0e8a557cbcb0785","placeholder":"​","style":"IPY_MODEL_df1f831a4908450f838d196fa93de06d","value":"tokenizer_config.json: 100%"}},"f6c842a395524212bb9e920effa69c3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_029ea485d3ad462ab8ae65f04d803fbd","max":529,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa186a3f47f240d0a1c8d8da08ca9f4f","value":529}},"a7eba23c45c54572be5a1767481d7b01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ee2f63fcf84e268bfa45a67500c975","placeholder":"​","style":"IPY_MODEL_3532da14f8ee4492a4d33d68898664cd","value":" 529/529 [00:00&lt;00:00, 66.1kB/s]"}},"1a31b8f091a14d58be9ea10fc5a28d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ede946377dd4471a0e8a557cbcb0785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1f831a4908450f838d196fa93de06d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"029ea485d3ad462ab8ae65f04d803fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa186a3f47f240d0a1c8d8da08ca9f4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09ee2f63fcf84e268bfa45a67500c975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3532da14f8ee4492a4d33d68898664cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18d9093ec096493880e949d0283ff8dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34a0c0f184e748fe8b49c9ee9ce65f64","IPY_MODEL_5f206f3f5c224525aef6f9d0167eebd0","IPY_MODEL_abe55661856248309350cab55cf15b78"],"layout":"IPY_MODEL_f1caf9e0026b4ccab80b5f23ea432a31"}},"34a0c0f184e748fe8b49c9ee9ce65f64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_902ac78a76814fc6bc045f78622c9fdf","placeholder":"​","style":"IPY_MODEL_86bd5f9e02cb4ce3b0d7263797400281","value":"sentencepiece.bpe.model: 100%"}},"5f206f3f5c224525aef6f9d0167eebd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95c152c1ef6f4e52836151d65e591798","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c4c93fc1fe04ef3919a2ddfd9bf4609","value":5069051}},"abe55661856248309350cab55cf15b78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56c0100781c644a09e4cf284063db3a0","placeholder":"​","style":"IPY_MODEL_aa8a0f7a75f245f999754557c244f125","value":" 5.07M/5.07M [00:01&lt;00:00, 2.71MB/s]"}},"f1caf9e0026b4ccab80b5f23ea432a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902ac78a76814fc6bc045f78622c9fdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86bd5f9e02cb4ce3b0d7263797400281":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95c152c1ef6f4e52836151d65e591798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c4c93fc1fe04ef3919a2ddfd9bf4609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56c0100781c644a09e4cf284063db3a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa8a0f7a75f245f999754557c244f125":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a443923993704bd9a703740f1a3e7ba8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8897dd1409344b7798ae45f18a572a02","IPY_MODEL_fdb14fd51225424da2e4c99a22e59857","IPY_MODEL_1cba807197cf48e6a025016c8649bc12"],"layout":"IPY_MODEL_62b68c29ca664507a3d7974adf5901d3"}},"8897dd1409344b7798ae45f18a572a02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_723c033fa19441bc89fffe9ed5059248","placeholder":"​","style":"IPY_MODEL_141e1f78f1424b609484c2c84fe7788c","value":"special_tokens_map.json: 100%"}},"fdb14fd51225424da2e4c99a22e59857":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5824558ee107463a8087b73667b6f05b","max":649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0519f3247d7c4037bdd01be13d42be4c","value":649}},"1cba807197cf48e6a025016c8649bc12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8068a427267d4923a4dc067774ef36b2","placeholder":"​","style":"IPY_MODEL_9341aa6c05fb41e997d6c2c69d2904ee","value":" 649/649 [00:00&lt;00:00, 89.5kB/s]"}},"62b68c29ca664507a3d7974adf5901d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"723c033fa19441bc89fffe9ed5059248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141e1f78f1424b609484c2c84fe7788c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5824558ee107463a8087b73667b6f05b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0519f3247d7c4037bdd01be13d42be4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8068a427267d4923a4dc067774ef36b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9341aa6c05fb41e997d6c2c69d2904ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2a686dbc7f344759c38b3fcfb10accd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caabb0ebb97c4a1aa913af24b71d69b5","IPY_MODEL_3ee98c6f81dc494a807731397ce3a24c","IPY_MODEL_f241a128c7404393a14e8ab498ebda1b"],"layout":"IPY_MODEL_197db049d2f7425085a07563a8ef3281"}},"caabb0ebb97c4a1aa913af24b71d69b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5722393dd60a431a893592db3f471dbe","placeholder":"​","style":"IPY_MODEL_8942ae17b30f482d9ab63af438a5d418","value":"config.json: "}},"3ee98c6f81dc494a807731397ce3a24c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92c4124f6d5f414bb4c75415eccf4924","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e959142120c9494a887ea670ffe0b7e9","value":1}},"f241a128c7404393a14e8ab498ebda1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6db7be8a37184513a4809e3aef92020c","placeholder":"​","style":"IPY_MODEL_64341d705f0f47c9a0a2e35720e428a5","value":" 1.43k/? [00:00&lt;00:00, 163kB/s]"}},"197db049d2f7425085a07563a8ef3281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5722393dd60a431a893592db3f471dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8942ae17b30f482d9ab63af438a5d418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92c4124f6d5f414bb4c75415eccf4924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e959142120c9494a887ea670ffe0b7e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6db7be8a37184513a4809e3aef92020c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64341d705f0f47c9a0a2e35720e428a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b079a44872304469bcc83e859989845f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00d5057f6c004b75a1f2c3b19f504837","IPY_MODEL_9836e7609d884e2184de4fd9ef7145f6","IPY_MODEL_7ade6e15636a4c84a8deab61e0c0e521"],"layout":"IPY_MODEL_8ca54b5db6bf4108b21e76a4237cbe65"}},"00d5057f6c004b75a1f2c3b19f504837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_126fdad0a6734ad49428446769899e56","placeholder":"​","style":"IPY_MODEL_cc08c14b59bb47c88f40a82825f74f04","value":"model.safetensors: 100%"}},"9836e7609d884e2184de4fd9ef7145f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b646ded4959473986aab04c9ec242af","max":2444578688,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c52c3c52e14443ea132b02075c44f53","value":2444578688}},"7ade6e15636a4c84a8deab61e0c0e521":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_253320a502544de794940a1e2e1725d6","placeholder":"​","style":"IPY_MODEL_a7c4e9d8e9da406384ce09b5f0246e4d","value":" 2.44G/2.44G [00:08&lt;00:00, 265MB/s]"}},"8ca54b5db6bf4108b21e76a4237cbe65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"126fdad0a6734ad49428446769899e56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc08c14b59bb47c88f40a82825f74f04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b646ded4959473986aab04c9ec242af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c52c3c52e14443ea132b02075c44f53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"253320a502544de794940a1e2e1725d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7c4e9d8e9da406384ce09b5f0246e4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6663ce7d307d4e51839a2e738d5491c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6406e1b50aa4572a761a3c0d073b86a","IPY_MODEL_9a7c54fd0df44be2b1d8726329352f4b","IPY_MODEL_afd802b01c3548b39142adc42c19ad22"],"layout":"IPY_MODEL_e40cc69558144b99a24c9c14a755dc17"}},"d6406e1b50aa4572a761a3c0d073b86a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc4a91756d964b708dd7ba22ac409e0c","placeholder":"​","style":"IPY_MODEL_bd45e03ac4814b9daa39c86cd13112ff","value":"generation_config.json: 100%"}},"9a7c54fd0df44be2b1d8726329352f4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eec4631dfaa458f89211626fa9793ed","max":261,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21265e131d204b7a896527d42ce125d9","value":261}},"afd802b01c3548b39142adc42c19ad22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b2a075b4c0a495189424d7ec33381fa","placeholder":"​","style":"IPY_MODEL_0fda6526676d420ba8fc7373294e393f","value":" 261/261 [00:00&lt;00:00, 33.1kB/s]"}},"e40cc69558144b99a24c9c14a755dc17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4a91756d964b708dd7ba22ac409e0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd45e03ac4814b9daa39c86cd13112ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eec4631dfaa458f89211626fa9793ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21265e131d204b7a896527d42ce125d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b2a075b4c0a495189424d7ec33381fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fda6526676d420ba8fc7373294e393f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c7c969d89ef426e9e62bd71520d2cd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e16c5791c4b4ccfbcce47406d2a6f1b","IPY_MODEL_9a5d61f7e474401e80d59bf9fa2e6425","IPY_MODEL_71bf193f26864466bcac946329b8b5fc"],"layout":"IPY_MODEL_61b7c156aee143c584a4c4ef079b72c0"}},"9e16c5791c4b4ccfbcce47406d2a6f1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a540a683927241dfa7fc158970f3c8d6","placeholder":"​","style":"IPY_MODEL_f9b206d166494c5aae8d212915f1b25f","value":"Map: 100%"}},"9a5d61f7e474401e80d59bf9fa2e6425":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffce4dfc3c144bcca3f1b69d6f1be283","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3468b8a16ac145d6943802df11a850de","value":8000}},"71bf193f26864466bcac946329b8b5fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_506878aba6294084a7708bd50ce9ea4f","placeholder":"​","style":"IPY_MODEL_1a84d424e51a4bcd83abf2a8e7c56dbc","value":" 8000/8000 [00:00&lt;00:00, 10602.33 examples/s]"}},"61b7c156aee143c584a4c4ef079b72c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a540a683927241dfa7fc158970f3c8d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b206d166494c5aae8d212915f1b25f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffce4dfc3c144bcca3f1b69d6f1be283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3468b8a16ac145d6943802df11a850de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"506878aba6294084a7708bd50ce9ea4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a84d424e51a4bcd83abf2a8e7c56dbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c07e64fdc44b49b4e9bd5bde915b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6195bd6c4a574a16a6d7acbb461e6608","IPY_MODEL_d382ff94d8ff4294921b11d996ba1abe","IPY_MODEL_86f3ea8dd5db446b947ade914b7d14d3"],"layout":"IPY_MODEL_1d0e49130180484e878769f5007b5857"}},"6195bd6c4a574a16a6d7acbb461e6608":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_635955263c4b4f7bb93df891f17890bf","placeholder":"​","style":"IPY_MODEL_4f13a67a10104a28910d0afff1b86817","value":"Map: 100%"}},"d382ff94d8ff4294921b11d996ba1abe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c3d2eb2890483fb7870c17244cd611","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f24c74fdf1142a08fb012d9e4e243b3","value":1000}},"86f3ea8dd5db446b947ade914b7d14d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22a550bed16f404a9a00c206b7ea6ce3","placeholder":"​","style":"IPY_MODEL_ad0e8e7cf5444402aa0b6d710b0a3d2b","value":" 1000/1000 [00:00&lt;00:00, 10496.39 examples/s]"}},"1d0e49130180484e878769f5007b5857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"635955263c4b4f7bb93df891f17890bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f13a67a10104a28910d0afff1b86817":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51c3d2eb2890483fb7870c17244cd611":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f24c74fdf1142a08fb012d9e4e243b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22a550bed16f404a9a00c206b7ea6ce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad0e8e7cf5444402aa0b6d710b0a3d2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c4a34ecf1d14729995bef3b57b3ec9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54c0c759e476463ba73fb279665169c2","IPY_MODEL_d501632bc0324c61b22b77c22fd42d96","IPY_MODEL_291e3587e9eb4e40a8557cbc2bf5f8d7"],"layout":"IPY_MODEL_186cee8223d24461b26380f35b26ec4c"}},"54c0c759e476463ba73fb279665169c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0325f6ea8a24438e9cbd7eee60f4f0ea","placeholder":"​","style":"IPY_MODEL_75743a710309493f94808e2779d86a4b","value":"Map: 100%"}},"d501632bc0324c61b22b77c22fd42d96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8259d36fac384ca4a1f4aa7f2498c3e5","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f286567bceaf4bd0ad8589b4278df7b5","value":8000}},"291e3587e9eb4e40a8557cbc2bf5f8d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_920e5cedcb874399af3cb023bcce9924","placeholder":"​","style":"IPY_MODEL_df4c37d4759c4c648f532b63210c5a6e","value":" 8000/8000 [00:00&lt;00:00, 10823.32 examples/s]"}},"186cee8223d24461b26380f35b26ec4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0325f6ea8a24438e9cbd7eee60f4f0ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75743a710309493f94808e2779d86a4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8259d36fac384ca4a1f4aa7f2498c3e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f286567bceaf4bd0ad8589b4278df7b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"920e5cedcb874399af3cb023bcce9924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df4c37d4759c4c648f532b63210c5a6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec9b39331cb94a0e9d2a974be0ce12fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a801c9a66834f1eb3d69cbc8239ef3b","IPY_MODEL_a19b4c564394455b8577261aaac77ec2","IPY_MODEL_7c8ad6d685d346a8845e8c0de8482885"],"layout":"IPY_MODEL_77a088f73c6640f3bd08c63d60b86d45"}},"6a801c9a66834f1eb3d69cbc8239ef3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_624aabd0de644db9a737eb464fdedf1d","placeholder":"​","style":"IPY_MODEL_6348691909844dc9a185f6194438e8e6","value":"Map: 100%"}},"a19b4c564394455b8577261aaac77ec2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc39b50cbb734ffea5d68a16522e9e46","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_371e4a18f88447fb9ee33878519ca155","value":1000}},"7c8ad6d685d346a8845e8c0de8482885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3326f991ff0f4bfab59b29fa2d49ef09","placeholder":"​","style":"IPY_MODEL_a01259bbbb6c460583b7bf9c85c3c41c","value":" 1000/1000 [00:00&lt;00:00, 10266.17 examples/s]"}},"77a088f73c6640f3bd08c63d60b86d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"624aabd0de644db9a737eb464fdedf1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6348691909844dc9a185f6194438e8e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc39b50cbb734ffea5d68a16522e9e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"371e4a18f88447fb9ee33878519ca155":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3326f991ff0f4bfab59b29fa2d49ef09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a01259bbbb6c460583b7bf9c85c3c41c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"uskLGUh7G4rq","executionInfo":{"status":"error","timestamp":1762330964255,"user_tz":-540,"elapsed":40885,"user":{"displayName":"Ah-reum Lee","userId":"08227880159288094050"}},"outputId":"21d13f58-9c26-49ec-94ee-32c97c8ebef8"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","mBART-50 Fine-tuning (NLLB-200 Configuration)\n","======================================================================\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4250920067.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mMBartForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mMBart50TokenizerFast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mcache_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDynamicCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoderDecoderCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from ...modeling_attn_mask_utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mAttentionMaskConverter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_deepspeed_zero3_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fsdp_managed_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_masks_for_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtensionsTrie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/masking_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_torch_greater_or_equal_than_2_6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_wrapped_higher_order_op\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformGetItemToIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m         euler_poly, andre_poly)\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpartfrac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapart_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massemble_partfrac_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/partfrac.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mxthreaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpublic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/utilities/decorator.py\u001b[0m in \u001b[0;36mxthreaded\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mthreaded_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/utilities/decorator.py\u001b[0m in \u001b[0;36mthreaded_factory\u001b[0;34m(func, use_add)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"A factory for ``threaded`` decorators. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrices\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrixBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/matrices/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNonSquareMatrixError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrixKind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from .dense import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mGramSchmidt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasoratian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjordan_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlist2numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix2numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_multiply_elementwise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/matrices/dense.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_cholesky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_LDLdecomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatrixbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrixBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrepmatrix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMutableRepMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msolvers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_lower_triangular_solve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_upper_triangular_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/matrices/matrixbase.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_highest_priority\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzzy_and\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFuzzyBool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDimArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/tensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindex_methods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_contraction_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from .array import (MutableDenseNDimArray, ImmutableDenseNDimArray,\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mMutableSparseNDimArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImmutableSparseNDimArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDimArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorproduct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtensorcontraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordiagonal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderive_by_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutedims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\"\"\"\n","mBART-50 Fine-tuning with NLLB-200 Configuration\n","Optimized for Colab Pro+ (A100/V100)\n","\"\"\"\n","\n","# ============================================================================\n","# 1. 환경 설정 및 라이브러리 설치\n","# ============================================================================\n","print(\"=\"*70)\n","print(\"mBART-50 Fine-tuning (NLLB-200 Configuration)\")\n","print(\"=\"*70)\n","\n","!pip install transformers datasets sentencepiece accelerate -q\n","\n","import pandas as pd\n","import torch\n","from transformers import (\n","    MBartForConditionalGeneration,\n","    MBart50TokenizerFast,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from datasets import Dataset\n","from google.colab import files, drive\n","import time\n","from datetime import timedelta\n","import os\n","\n","# ============================================================================\n","# 2. GPU 확인\n","# ============================================================================\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"\\n{'='*70}\")\n","print(\"GPU Information\")\n","print(f\"{'='*70}\")\n","print(f\"Device: {device}\")\n","if device == \"cuda\":\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","    print(f\"GPU: {gpu_name}\")\n","    print(f\"Total Memory: {gpu_memory:.1f} GB\")\n","\n","    # Colab Pro+ 확인\n","    if \"A100\" in gpu_name or \"V100\" in gpu_name:\n","        print(\"✓ Colab Pro+ GPU detected!\")\n","    else:\n","        print(\"⚠ Warning: This configuration requires Colab Pro+ (A100/V100)\")\n","\n","# ============================================================================\n","# 3. Google Drive 마운트\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Mounting Google Drive\")\n","print(f\"{'='*70}\")\n","drive.mount('/content/drive')\n","\n","# 저장 경로 설정\n","OUTPUT_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_config\"\n","FINAL_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_final\"\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","print(f\"✓ Output directory: {OUTPUT_DIR}\")\n","\n","# ============================================================================\n","# 4. 데이터 파일 업로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Upload Training Data\")\n","print(f\"{'='*70}\")\n","print(\"Please upload train_v2.csv and dev_v2.csv:\")\n","\n","uploaded = files.upload()\n","\n","# 업로드된 파일 확인\n","uploaded_files = list(uploaded.keys())\n","print(f\"\\n✓ Uploaded files: {uploaded_files}\")\n","\n","# 데이터 로드\n","if 'train_v2.csv' not in uploaded_files or 'dev_v2.csv' not in uploaded_files:\n","    raise FileNotFoundError(\"train_v2.csv and dev_v2.csv are required!\")\n","\n","train_df = pd.read_csv('train_v2.csv')\n","val_df = pd.read_csv('dev_v2.csv')\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Dataset Information\")\n","print(f\"{'='*70}\")\n","print(f\"Train samples: {len(train_df):,}\")\n","print(f\"Validation samples: {len(val_df):,}\")\n","print(f\"\\nSample data:\")\n","print(train_df.head(2))\n","\n","# ============================================================================\n","# 5. 모델 및 토크나이저 로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Loading Model and Tokenizer\")\n","print(f\"{'='*70}\")\n","\n","MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n","print(f\"Model: {MODEL_NAME}\")\n","\n","tokenizer = MBart50TokenizerFast.from_pretrained(\n","    MODEL_NAME,\n","    src_lang=\"ru_RU\",\n","    tgt_lang=\"ko_KR\"\n",")\n","print(\"✓ Tokenizer loaded\")\n","\n","model = MBartForConditionalGeneration.from_pretrained(MODEL_NAME)\n","print(f\"✓ Model loaded: {model.num_parameters():,} parameters\")\n","\n","# ============================================================================\n","# 6. 데이터 전처리 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Data Preprocessing (NLLB-200 Config)\")\n","print(f\"{'='*70}\")\n","\n","# NLLB-200 설정값\n","MAX_LENGTH = 256  # 최대 시퀀스 길이\n","\n","def preprocess_function(examples):\n","    \"\"\"NLLB-200 방식의 전처리\"\"\"\n","    tokenizer.src_lang = \"ru_RU\"\n","\n","    # Source 언어 토크나이징\n","    inputs = tokenizer(\n","        examples['ru'],\n","        max_length=MAX_LENGTH,\n","        truncation=True,\n","        padding=False\n","    )\n","\n","    # Target 언어 토크나이징\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples['ko'],\n","            max_length=MAX_LENGTH,\n","            truncation=True,\n","            padding=False\n","        )\n","\n","    inputs['labels'] = labels['input_ids']\n","    return inputs\n","\n","# 데이터셋 변환\n","train_dataset = Dataset.from_pandas(train_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=train_df.columns.tolist()\n",")\n","\n","val_dataset = Dataset.from_pandas(val_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=val_df.columns.tolist()\n",")\n","\n","# Data Collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer,\n","    model=model,\n","    padding=True\n",")\n","\n","print(f\"✓ Train dataset: {len(train_dataset):,} samples\")\n","print(f\"✓ Validation dataset: {len(val_dataset):,} samples\")\n","print(f\"✓ MAX_LENGTH: {MAX_LENGTH}\")\n","\n","# ============================================================================\n","# 7. 학습 설정 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Training Configuration (NLLB-200 Settings)\")\n","print(f\"{'='*70}\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    # 기본 설정\n","    output_dir=OUTPUT_DIR,\n","\n","    # 학습 설정\n","    num_train_epochs=3,                      # 에포크 수\n","    per_device_train_batch_size=8,           # 배치 크기 (GPU 당)\n","    gradient_accumulation_steps=2,           # 그래디언트 누적 (실질 배치 16)\n","\n","    # 학습률 및 최적화\n","    learning_rate=1e-5,                      # 학습률 (1×10⁻⁵)\n","    warmup_steps=300,                        # 워밍업 단계\n","\n","    # 로깅 및 저장\n","    logging_steps=100,                       # 로그 기록 간격\n","    save_steps=500,                          # 모델 저장 간격\n","    eval_steps=500,                          # 검증 실행 간격\n","\n","    # 저장 전략\n","    save_strategy=\"steps\",\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3,                      # 최대 체크포인트 수\n","\n","    # 메모리 최적화\n","    fp16=True,                               # FP16 혼합 정밀도\n","\n","    # 기타\n","    report_to=\"none\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n","    greater_is_better=False,\n","    predict_with_generate=False,             # 평가 시 생성 비활성화 (속도 향상)\n",")\n","\n","print(f\"\"\"\n","Configuration Summary:\n","{'='*70}\n","Model: {MODEL_NAME}\n","Epochs: 3\n","Batch size per device: 8\n","Gradient accumulation: 2\n","Effective batch size: 16\n","Learning rate: 1e-5\n","Warmup steps: 300\n","MAX_LENGTH: 256\n","FP16: Enabled\n","{'='*70}\n","\"\"\")\n","\n","# ============================================================================\n","# 8. Trainer 초기화\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Initializing Trainer\")\n","print(f\"{'='*70}\")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","print(\"✓ Trainer initialized\")\n","\n","# GPU 캐시 정리\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"✓ GPU cache cleared\")\n","\n","# ============================================================================\n","# 9. 학습 실행\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"TRAINING START\")\n","print(f\"{'='*70}\")\n","\n","start_time = time.time()\n","print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","\n","try:\n","    # 학습 시작\n","    train_result = trainer.train()\n","\n","    # 학습 완료\n","    success = True\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING COMPLETED!\")\n","    print(f\"{'='*70}\")\n","\n","except torch.cuda.OutOfMemoryError as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"OOM ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(\"Out of memory error occurred.\")\n","    print(\"\\nOptions:\")\n","    print(\"  1. Reduce batch_size to 4\")\n","    print(\"  2. Increase gradient_accumulation_steps to 4\")\n","    print(\"  3. Reduce MAX_LENGTH to 128\")\n","    success = False\n","\n","except Exception as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(f\"Error: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    success = False\n","\n","# 학습 시간 계산\n","duration = time.time() - start_time\n","duration_str = str(timedelta(seconds=int(duration)))\n","\n","# ============================================================================\n","# 10. 모델 저장 및 결과 정리\n","# ============================================================================\n","if success:\n","    print(f\"\\n{'='*70}\")\n","    print(\"Saving Model\")\n","    print(f\"{'='*70}\")\n","\n","    # 최종 모델 저장\n","    trainer.save_model(FINAL_DIR)\n","    tokenizer.save_pretrained(FINAL_DIR)\n","\n","    print(f\"✓ Model saved to: {FINAL_DIR}\")\n","\n","    # 학습 결과 요약\n","    summary = f\"\"\"\n","{'='*70}\n","mBART-50 Fine-tuning Results (NLLB-200 Configuration)\n","{'='*70}\n","\n","Dataset:\n","  - Train samples: {len(train_dataset):,}\n","  - Validation samples: {len(val_dataset):,}\n","\n","Model:\n","  - Name: {MODEL_NAME}\n","  - Parameters: {model.num_parameters():,}\n","\n","Configuration:\n","  - Epochs: 3\n","  - Batch size: 8\n","  - Gradient accumulation: 2\n","  - Effective batch size: 16\n","  - Learning rate: 1e-5\n","  - Warmup steps: 300\n","  - MAX_LENGTH: 256\n","  - FP16: Enabled\n","\n","Training:\n","  - Duration: {duration_str}\n","  - Final loss: {train_result.training_loss:.4f}\n","\n","Saved:\n","  - Location: {FINAL_DIR}\n","\n","{'='*70}\n","Training completed successfully!\n","{'='*70}\n","\"\"\"\n","\n","    print(summary)\n","\n","    # 요약 파일 저장\n","    with open(f\"{FINAL_DIR}/training_summary.txt\", 'w', encoding='utf-8') as f:\n","        f.write(summary)\n","\n","    print(f\"✓ Summary saved to: {FINAL_DIR}/training_summary.txt\")\n","\n","    # 학습 로그 저장\n","    if hasattr(trainer.state, 'log_history'):\n","        import json\n","        with open(f\"{FINAL_DIR}/training_logs.json\", 'w', encoding='utf-8') as f:\n","            json.dump(trainer.state.log_history, f, indent=2)\n","        print(f\"✓ Training logs saved to: {FINAL_DIR}/training_logs.json\")\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"SUCCESS! 🎉\")\n","    print(f\"{'='*70}\")\n","\n","else:\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING FAILED\")\n","    print(f\"{'='*70}\")\n","    print(f\"Duration: {duration_str}\")\n","    print(\"\\nPlease check the error messages above and try again.\")\n","\n","# ============================================================================\n","# 11. 메모리 정리\n","# ============================================================================\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"\\n✓ GPU memory cleared\")\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Script completed\")\n","print(f\"{'='*70}\")"]},{"cell_type":"code","source":["\"\"\"\n","mBART-50 Fine-tuning with NLLB-200 Configuration\n","Optimized for Colab Pro+ (A100/V100)\n","\"\"\"\n","\n","# ============================================================================\n","# 1. 환경 설정 및 라이브러리 설치\n","# ============================================================================\n","print(\"=\"*70)\n","print(\"mBART-50 Fine-tuning (NLLB-200 Configuration)\")\n","print(\"=\"*70)\n","\n","!pip install transformers datasets sentencepiece accelerate -q\n","\n","import pandas as pd\n","import torch\n","from transformers import (\n","    MBartForConditionalGeneration,\n","    MBart50TokenizerFast,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from datasets import Dataset\n","from google.colab import files, drive\n","import time\n","from datetime import timedelta\n","import os\n","\n","# ============================================================================\n","# 2. GPU 확인\n","# ============================================================================\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"\\n{'='*70}\")\n","print(\"GPU Information\")\n","print(f\"{'='*70}\")\n","print(f\"Device: {device}\")\n","if device == \"cuda\":\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","    print(f\"GPU: {gpu_name}\")\n","    print(f\"Total Memory: {gpu_memory:.1f} GB\")\n","\n","    # Colab Pro+ 확인\n","    if \"A100\" in gpu_name or \"V100\" in gpu_name:\n","        print(\"✓ Colab Pro+ GPU detected!\")\n","    else:\n","        print(\"⚠ Warning: This configuration requires Colab Pro+ (A100/V100)\")\n","\n","# ============================================================================\n","# 3. Google Drive 마운트\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Mounting Google Drive\")\n","print(f\"{'='*70}\")\n","drive.mount('/content/drive')\n","\n","# 저장 경로 설정\n","OUTPUT_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_config\"\n","FINAL_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_final\"\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","print(f\"✓ Output directory: {OUTPUT_DIR}\")\n","\n","# ============================================================================\n","# 4. 데이터 파일 업로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Upload Training Data\")\n","print(f\"{'='*70}\")\n","print(\"Please upload train_v2.csv and dev_v2.csv:\")\n","\n","uploaded = files.upload()\n","\n","# 업로드된 파일 확인\n","uploaded_files = list(uploaded.keys())\n","print(f\"\\n✓ Uploaded files: {uploaded_files}\")\n","\n","# 데이터 로드\n","if 'train_v2.csv' not in uploaded_files or 'dev_v2.csv' not in uploaded_files:\n","    raise FileNotFoundError(\"train_v2.csv and dev_v2.csv are required!\")\n","\n","train_df = pd.read_csv('train_v2.csv')\n","val_df = pd.read_csv('dev_v2.csv')\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Dataset Information\")\n","print(f\"{'='*70}\")\n","print(f\"Train samples: {len(train_df):,}\")\n","print(f\"Validation samples: {len(val_df):,}\")\n","print(f\"\\nSample data:\")\n","print(train_df.head(2))\n","\n","# ============================================================================\n","# 5. 모델 및 토크나이저 로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Loading Model and Tokenizer\")\n","print(f\"{'='*70}\")\n","\n","MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n","print(f\"Model: {MODEL_NAME}\")\n","\n","tokenizer = MBart50TokenizerFast.from_pretrained(\n","    MODEL_NAME,\n","    src_lang=\"ru_RU\",\n","    tgt_lang=\"ko_KR\"\n",")\n","print(\"✓ Tokenizer loaded\")\n","\n","model = MBartForConditionalGeneration.from_pretrained(MODEL_NAME)\n","print(f\"✓ Model loaded: {model.num_parameters():,} parameters\")\n","\n","# ============================================================================\n","# 6. 데이터 전처리 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Data Preprocessing (NLLB-200 Config)\")\n","print(f\"{'='*70}\")\n","\n","# NLLB-200 설정값\n","MAX_LENGTH = 256  # 최대 시퀀스 길이\n","\n","def preprocess_function(examples):\n","    \"\"\"NLLB-200 방식의 전처리\"\"\"\n","    tokenizer.src_lang = \"ru_RU\"\n","\n","    # Source 언어 토크나이징\n","    inputs = tokenizer(\n","        examples['ru'],\n","        max_length=MAX_LENGTH,\n","        truncation=True,\n","        padding=False\n","    )\n","\n","    # Target 언어 토크나이징\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples['ko'],\n","            max_length=MAX_LENGTH,\n","            truncation=True,\n","            padding=False\n","        )\n","\n","    inputs['labels'] = labels['input_ids']\n","    return inputs\n","\n","# 데이터셋 변환\n","train_dataset = Dataset.from_pandas(train_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=train_df.columns.tolist()\n",")\n","\n","val_dataset = Dataset.from_pandas(val_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=val_df.columns.tolist()\n",")\n","\n","# Data Collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer,\n","    model=model,\n","    padding=True\n",")\n","\n","print(f\"✓ Train dataset: {len(train_dataset):,} samples\")\n","print(f\"✓ Validation dataset: {len(val_dataset):,} samples\")\n","print(f\"✓ MAX_LENGTH: {MAX_LENGTH}\")\n","\n","# ============================================================================\n","# 7. 학습 설정 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Training Configuration (NLLB-200 Settings)\")\n","print(f\"{'='*70}\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    # 기본 설정\n","    output_dir=OUTPUT_DIR,\n","\n","    # 학습 설정\n","    num_train_epochs=3,                      # 에포크 수\n","    per_device_train_batch_size=8,           # 배치 크기 (GPU 당)\n","    gradient_accumulation_steps=2,           # 그래디언트 누적 (실질 배치 16)\n","\n","    # 학습률 및 최적화\n","    learning_rate=1e-5,                      # 학습률 (1×10⁻⁵)\n","    warmup_steps=300,                        # 워밍업 단계\n","\n","    # 로깅 및 저장\n","    logging_steps=100,                       # 로그 기록 간격\n","    save_steps=500,                          # 모델 저장 간격\n","    eval_steps=500,                          # 검증 실행 간격\n","\n","    # 저장 전략\n","    save_strategy=\"steps\",\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3,                      # 최대 체크포인트 수\n","\n","    # 메모리 최적화\n","    fp16=True,                               # FP16 혼합 정밀도\n","\n","    # 기타\n","    report_to=\"none\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n","    greater_is_better=False,\n","    predict_with_generate=False,             # 평가 시 생성 비활성화 (속도 향상)\n",")\n","\n","print(f\"\"\"\n","Configuration Summary:\n","{'='*70}\n","Model: {MODEL_NAME}\n","Epochs: 3\n","Batch size per device: 8\n","Gradient accumulation: 2\n","Effective batch size: 16\n","Learning rate: 1e-5\n","Warmup steps: 300\n","MAX_LENGTH: 256\n","FP16: Enabled\n","{'='*70}\n","\"\"\")\n","\n","# ============================================================================\n","# 8. Trainer 초기화\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Initializing Trainer\")\n","print(f\"{'='*70}\")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","print(\"✓ Trainer initialized\")\n","\n","# GPU 캐시 정리\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"✓ GPU cache cleared\")\n","\n","# ============================================================================\n","# 9. 학습 실행\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"TRAINING START\")\n","print(f\"{'='*70}\")\n","\n","start_time = time.time()\n","print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","\n","try:\n","    # 학습 시작\n","    train_result = trainer.train()\n","\n","    # 학습 완료\n","    success = True\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING COMPLETED!\")\n","    print(f\"{'='*70}\")\n","\n","except torch.cuda.OutOfMemoryError as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"OOM ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(\"Out of memory error occurred.\")\n","    print(\"\\nOptions:\")\n","    print(\"  1. Reduce batch_size to 4\")\n","    print(\"  2. Increase gradient_accumulation_steps to 4\")\n","    print(\"  3. Reduce MAX_LENGTH to 128\")\n","    success = False\n","\n","except Exception as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(f\"Error: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    success = False\n","\n","# 학습 시간 계산\n","duration = time.time() - start_time\n","duration_str = str(timedelta(seconds=int(duration)))\n","\n","# ============================================================================\n","# 10. 모델 저장 및 결과 정리\n","# ============================================================================\n","if success:\n","    print(f\"\\n{'='*70}\")\n","    print(\"Saving Model\")\n","    print(f\"{'='*70}\")\n","\n","    # 최종 모델 저장\n","    trainer.save_model(FINAL_DIR)\n","    tokenizer.save_pretrained(FINAL_DIR)\n","\n","    print(f\"✓ Model saved to: {FINAL_DIR}\")\n","\n","    # 학습 결과 요약\n","    summary = f\"\"\"\n","{'='*70}\n","mBART-50 Fine-tuning Results (NLLB-200 Configuration)\n","{'='*70}\n","\n","Dataset:\n","  - Train samples: {len(train_dataset):,}\n","  - Validation samples: {len(val_dataset):,}\n","\n","Model:\n","  - Name: {MODEL_NAME}\n","  - Parameters: {model.num_parameters():,}\n","\n","Configuration:\n","  - Epochs: 3\n","  - Batch size: 8\n","  - Gradient accumulation: 2\n","  - Effective batch size: 16\n","  - Learning rate: 1e-5\n","  - Warmup steps: 300\n","  - MAX_LENGTH: 256\n","  - FP16: Enabled\n","\n","Training:\n","  - Duration: {duration_str}\n","  - Final loss: {train_result.training_loss:.4f}\n","\n","Saved:\n","  - Location: {FINAL_DIR}\n","\n","{'='*70}\n","Training completed successfully!\n","{'='*70}\n","\"\"\"\n","\n","    print(summary)\n","\n","    # 요약 파일 저장\n","    with open(f\"{FINAL_DIR}/training_summary.txt\", 'w', encoding='utf-8') as f:\n","        f.write(summary)\n","\n","    print(f\"✓ Summary saved to: {FINAL_DIR}/training_summary.txt\")\n","\n","    # 학습 로그 저장\n","    if hasattr(trainer.state, 'log_history'):\n","        import json\n","        with open(f\"{FINAL_DIR}/training_logs.json\", 'w', encoding='utf-8') as f:\n","            json.dump(trainer.state.log_history, f, indent=2)\n","        print(f\"✓ Training logs saved to: {FINAL_DIR}/training_logs.json\")\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"SUCCESS! 🎉\")\n","    print(f\"{'='*70}\")\n","\n","else:\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING FAILED\")\n","    print(f\"{'='*70}\")\n","    print(f\"Duration: {duration_str}\")\n","    print(\"\\nPlease check the error messages above and try again.\")\n","\n","# ============================================================================\n","# 11. 메모리 정리\n","# ============================================================================\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"\\n✓ GPU memory cleared\")\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Script completed\")\n","print(f\"{'='*70}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["643817c7567b49ada66b7b5e3b21602c","6382445c84874b3cb2b5180d2d983f36","f6c842a395524212bb9e920effa69c3f","a7eba23c45c54572be5a1767481d7b01","1a31b8f091a14d58be9ea10fc5a28d37","3ede946377dd4471a0e8a557cbcb0785","df1f831a4908450f838d196fa93de06d","029ea485d3ad462ab8ae65f04d803fbd","fa186a3f47f240d0a1c8d8da08ca9f4f","09ee2f63fcf84e268bfa45a67500c975","3532da14f8ee4492a4d33d68898664cd","18d9093ec096493880e949d0283ff8dc","34a0c0f184e748fe8b49c9ee9ce65f64","5f206f3f5c224525aef6f9d0167eebd0","abe55661856248309350cab55cf15b78","f1caf9e0026b4ccab80b5f23ea432a31","902ac78a76814fc6bc045f78622c9fdf","86bd5f9e02cb4ce3b0d7263797400281","95c152c1ef6f4e52836151d65e591798","7c4c93fc1fe04ef3919a2ddfd9bf4609","56c0100781c644a09e4cf284063db3a0","aa8a0f7a75f245f999754557c244f125","a443923993704bd9a703740f1a3e7ba8","8897dd1409344b7798ae45f18a572a02","fdb14fd51225424da2e4c99a22e59857","1cba807197cf48e6a025016c8649bc12","62b68c29ca664507a3d7974adf5901d3","723c033fa19441bc89fffe9ed5059248","141e1f78f1424b609484c2c84fe7788c","5824558ee107463a8087b73667b6f05b","0519f3247d7c4037bdd01be13d42be4c","8068a427267d4923a4dc067774ef36b2","9341aa6c05fb41e997d6c2c69d2904ee","f2a686dbc7f344759c38b3fcfb10accd","caabb0ebb97c4a1aa913af24b71d69b5","3ee98c6f81dc494a807731397ce3a24c","f241a128c7404393a14e8ab498ebda1b","197db049d2f7425085a07563a8ef3281","5722393dd60a431a893592db3f471dbe","8942ae17b30f482d9ab63af438a5d418","92c4124f6d5f414bb4c75415eccf4924","e959142120c9494a887ea670ffe0b7e9","6db7be8a37184513a4809e3aef92020c","64341d705f0f47c9a0a2e35720e428a5","b079a44872304469bcc83e859989845f","00d5057f6c004b75a1f2c3b19f504837","9836e7609d884e2184de4fd9ef7145f6","7ade6e15636a4c84a8deab61e0c0e521","8ca54b5db6bf4108b21e76a4237cbe65","126fdad0a6734ad49428446769899e56","cc08c14b59bb47c88f40a82825f74f04","9b646ded4959473986aab04c9ec242af","4c52c3c52e14443ea132b02075c44f53","253320a502544de794940a1e2e1725d6","a7c4e9d8e9da406384ce09b5f0246e4d","6663ce7d307d4e51839a2e738d5491c1","d6406e1b50aa4572a761a3c0d073b86a","9a7c54fd0df44be2b1d8726329352f4b","afd802b01c3548b39142adc42c19ad22","e40cc69558144b99a24c9c14a755dc17","bc4a91756d964b708dd7ba22ac409e0c","bd45e03ac4814b9daa39c86cd13112ff","3eec4631dfaa458f89211626fa9793ed","21265e131d204b7a896527d42ce125d9","0b2a075b4c0a495189424d7ec33381fa","0fda6526676d420ba8fc7373294e393f","8c7c969d89ef426e9e62bd71520d2cd3","9e16c5791c4b4ccfbcce47406d2a6f1b","9a5d61f7e474401e80d59bf9fa2e6425","71bf193f26864466bcac946329b8b5fc","61b7c156aee143c584a4c4ef079b72c0","a540a683927241dfa7fc158970f3c8d6","f9b206d166494c5aae8d212915f1b25f","ffce4dfc3c144bcca3f1b69d6f1be283","3468b8a16ac145d6943802df11a850de","506878aba6294084a7708bd50ce9ea4f","1a84d424e51a4bcd83abf2a8e7c56dbc","13c07e64fdc44b49b4e9bd5bde915b9e","6195bd6c4a574a16a6d7acbb461e6608","d382ff94d8ff4294921b11d996ba1abe","86f3ea8dd5db446b947ade914b7d14d3","1d0e49130180484e878769f5007b5857","635955263c4b4f7bb93df891f17890bf","4f13a67a10104a28910d0afff1b86817","51c3d2eb2890483fb7870c17244cd611","5f24c74fdf1142a08fb012d9e4e243b3","22a550bed16f404a9a00c206b7ea6ce3","ad0e8e7cf5444402aa0b6d710b0a3d2b"]},"id":"YV9KJoHnHMW-","executionInfo":{"status":"error","timestamp":1762331112804,"user_tz":-540,"elapsed":124416,"user":{"displayName":"Ah-reum Lee","userId":"08227880159288094050"}},"outputId":"ccb86632-888a-4147-e7e6-90152f398727"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","mBART-50 Fine-tuning (NLLB-200 Configuration)\n","======================================================================\n","\n","======================================================================\n","GPU Information\n","======================================================================\n","Device: cuda\n","GPU: NVIDIA A100-SXM4-40GB\n","Total Memory: 42.5 GB\n","✓ Colab Pro+ GPU detected!\n","\n","======================================================================\n","Mounting Google Drive\n","======================================================================\n","Mounted at /content/drive\n","✓ Output directory: /content/drive/MyDrive/mbart_legal_nllb_config\n","\n","======================================================================\n","Upload Training Data\n","======================================================================\n","Please upload train_v2.csv and dev_v2.csv:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-61b2bdc0-d264-413c-9ce4-0dcacecf0bb0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-61b2bdc0-d264-413c-9ce4-0dcacecf0bb0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev_v2.csv to dev_v2.csv\n","Saving train_v2.csv to train_v2.csv\n","\n","✓ Uploaded files: ['dev_v2.csv', 'train_v2.csv']\n","\n","======================================================================\n","Dataset Information\n","======================================================================\n","Train samples: 8,000\n","Validation samples: 1,000\n","\n","Sample data:\n","   id                                                 ru  \\\n","0   1  Российская Федерация - Россия есть демократиче...   \n","1   2  Наименования Российская Федерация и Россия рав...   \n","\n","                                             ko  \n","0  러시아연방, 즉 러시아는 공화국 통치 형태를 갖춘 민주주의 연방 법치 국가이다.  \n","1                 러시아연방과 러시아라는 명칭은 동일한 의미를 지닌다.  \n","\n","======================================================================\n","Loading Model and Tokenizer\n","======================================================================\n","Model: facebook/mbart-large-50-many-to-many-mmt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643817c7567b49ada66b7b5e3b21602c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d9093ec096493880e949d0283ff8dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a443923993704bd9a703740f1a3e7ba8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a686dbc7f344759c38b3fcfb10accd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Tokenizer loaded\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b079a44872304469bcc83e859989845f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6663ce7d307d4e51839a2e738d5491c1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Model loaded: 610,879,488 parameters\n","\n","======================================================================\n","Data Preprocessing (NLLB-200 Config)\n","======================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7c969d89ef426e9e62bd71520d2cd3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c07e64fdc44b49b4e9bd5bde915b9e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Train dataset: 8,000 samples\n","✓ Validation dataset: 1,000 samples\n","✓ MAX_LENGTH: 256\n","\n","======================================================================\n","Training Configuration (NLLB-200 Settings)\n","======================================================================\n"]},{"output_type":"error","ename":"TypeError","evalue":"Seq2SeqTrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4250920067.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'='*70}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m training_args = Seq2SeqTrainingArguments(\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;31m# 기본 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Seq2SeqTrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"]}]},{"cell_type":"code","source":["\"\"\"\n","mBART-50 Fine-tuning with NLLB-200 Configuration\n","Optimized for Colab Pro+ (A100/V100)\n","\"\"\"\n","\n","# ============================================================================\n","# 1. 환경 설정 및 라이브러리 설치\n","# ============================================================================\n","print(\"=\"*70)\n","print(\"mBART-50 Fine-tuning (NLLB-200 Configuration)\")\n","print(\"=\"*70)\n","\n","!pip install transformers datasets sentencepiece accelerate -q\n","\n","import pandas as pd\n","import torch\n","from transformers import (\n","    MBartForConditionalGeneration,\n","    MBart50TokenizerFast,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from datasets import Dataset\n","from google.colab import files, drive\n","import time\n","from datetime import timedelta\n","import os\n","\n","# ============================================================================\n","# 2. GPU 확인\n","# ============================================================================\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"\\n{'='*70}\")\n","print(\"GPU Information\")\n","print(f\"{'='*70}\")\n","print(f\"Device: {device}\")\n","if device == \"cuda\":\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","    print(f\"GPU: {gpu_name}\")\n","    print(f\"Total Memory: {gpu_memory:.1f} GB\")\n","\n","    # Colab Pro+ 확인\n","    if \"A100\" in gpu_name or \"V100\" in gpu_name:\n","        print(\"✓ Colab Pro+ GPU detected!\")\n","    else:\n","        print(\"⚠ Warning: This configuration requires Colab Pro+ (A100/V100)\")\n","\n","# ============================================================================\n","# 3. Google Drive 마운트\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Mounting Google Drive\")\n","print(f\"{'='*70}\")\n","drive.mount('/content/drive')\n","\n","# 저장 경로 설정\n","OUTPUT_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_config\"\n","FINAL_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_final\"\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","print(f\"✓ Output directory: {OUTPUT_DIR}\")\n","\n","# ============================================================================\n","# 4. 데이터 파일 업로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Upload Training Data\")\n","print(f\"{'='*70}\")\n","print(\"Please upload train_v2.csv and dev_v2.csv:\")\n","\n","uploaded = files.upload()\n","\n","# 업로드된 파일 확인\n","uploaded_files = list(uploaded.keys())\n","print(f\"\\n✓ Uploaded files: {uploaded_files}\")\n","\n","# 데이터 로드\n","if 'train_v2.csv' not in uploaded_files or 'dev_v2.csv' not in uploaded_files:\n","    raise FileNotFoundError(\"train_v2.csv and dev_v2.csv are required!\")\n","\n","train_df = pd.read_csv('train_v2.csv')\n","val_df = pd.read_csv('dev_v2.csv')\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Dataset Information\")\n","print(f\"{'='*70}\")\n","print(f\"Train samples: {len(train_df):,}\")\n","print(f\"Validation samples: {len(val_df):,}\")\n","print(f\"\\nSample data:\")\n","print(train_df.head(2))\n","\n","# ============================================================================\n","# 5. 모델 및 토크나이저 로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Loading Model and Tokenizer\")\n","print(f\"{'='*70}\")\n","\n","MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n","print(f\"Model: {MODEL_NAME}\")\n","\n","tokenizer = MBart50TokenizerFast.from_pretrained(\n","    MODEL_NAME,\n","    src_lang=\"ru_RU\",\n","    tgt_lang=\"ko_KR\"\n",")\n","print(\"✓ Tokenizer loaded\")\n","\n","model = MBartForConditionalGeneration.from_pretrained(MODEL_NAME)\n","print(f\"✓ Model loaded: {model.num_parameters():,} parameters\")\n","\n","# ============================================================================\n","# 6. 데이터 전처리 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Data Preprocessing (NLLB-200 Config)\")\n","print(f\"{'='*70}\")\n","\n","# NLLB-200 설정값\n","MAX_LENGTH = 256  # 최대 시퀀스 길이\n","\n","def preprocess_function(examples):\n","    \"\"\"NLLB-200 방식의 전처리\"\"\"\n","    tokenizer.src_lang = \"ru_RU\"\n","\n","    # Source 언어 토크나이징\n","    inputs = tokenizer(\n","        examples['ru'],\n","        max_length=MAX_LENGTH,\n","        truncation=True,\n","        padding=False\n","    )\n","\n","    # Target 언어 토크나이징\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples['ko'],\n","            max_length=MAX_LENGTH,\n","            truncation=True,\n","            padding=False\n","        )\n","\n","    inputs['labels'] = labels['input_ids']\n","    return inputs\n","\n","# 데이터셋 변환\n","train_dataset = Dataset.from_pandas(train_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=train_df.columns.tolist()\n",")\n","\n","val_dataset = Dataset.from_pandas(val_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=val_df.columns.tolist()\n",")\n","\n","# Data Collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer,\n","    model=model,\n","    padding=True\n",")\n","\n","print(f\"✓ Train dataset: {len(train_dataset):,} samples\")\n","print(f\"✓ Validation dataset: {len(val_dataset):,} samples\")\n","print(f\"✓ MAX_LENGTH: {MAX_LENGTH}\")\n","\n","# ============================================================================\n","# 7. 학습 설정 (NLLB-200 Configuration) - ✅ 수정됨\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Training Configuration (NLLB-200 Settings)\")\n","print(f\"{'='*70}\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    # 기본 설정\n","    output_dir=OUTPUT_DIR,\n","\n","    # 학습 설정\n","    num_train_epochs=3,                      # 에포크 수\n","    per_device_train_batch_size=8,           # 배치 크기 (GPU 당)\n","    gradient_accumulation_steps=2,           # 그래디언트 누적 (실질 배치 16)\n","\n","    # 학습률 및 최적화\n","    learning_rate=1e-5,                      # 학습률 (1×10⁻⁵)\n","    warmup_steps=300,                        # 워밍업 단계\n","\n","    # 로깅 및 저장\n","    logging_steps=100,                       # 로그 기록 간격\n","    save_steps=500,                          # 모델 저장 간격\n","    eval_steps=500,                          # 검증 실행 간격\n","\n","    # 저장 전략\n","    save_strategy=\"steps\",\n","    eval_strategy=\"steps\",                   # ✅ 수정: evaluation_strategy → eval_strategy\n","    save_total_limit=3,                      # 최대 체크포인트 수\n","\n","    # 메모리 최적화\n","    fp16=True,                               # FP16 혼합 정밀도\n","\n","    # 기타\n","    report_to=\"none\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n","    greater_is_better=False,\n","    predict_with_generate=False,             # 평가 시 생성 비활성화 (속도 향상)\n",")\n","\n","print(f\"\"\"\n","Configuration Summary:\n","{'='*70}\n","Model: {MODEL_NAME}\n","Epochs: 3\n","Batch size per device: 8\n","Gradient accumulation: 2\n","Effective batch size: 16\n","Learning rate: 1e-5\n","Warmup steps: 300\n","MAX_LENGTH: 256\n","FP16: Enabled\n","{'='*70}\n","\"\"\")\n","\n","# ============================================================================\n","# 8. Trainer 초기화\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Initializing Trainer\")\n","print(f\"{'='*70}\")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","print(\"✓ Trainer initialized\")\n","\n","# GPU 캐시 정리\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"✓ GPU cache cleared\")\n","\n","# ============================================================================\n","# 9. 학습 실행\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"TRAINING START\")\n","print(f\"{'='*70}\")\n","\n","start_time = time.time()\n","print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","\n","try:\n","    # 학습 시작\n","    train_result = trainer.train()\n","\n","    # 학습 완료\n","    success = True\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING COMPLETED!\")\n","    print(f\"{'='*70}\")\n","\n","except torch.cuda.OutOfMemoryError as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"OOM ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(\"Out of memory error occurred.\")\n","    print(\"\\nOptions:\")\n","    print(\"  1. Reduce batch_size to 4\")\n","    print(\"  2. Increase gradient_accumulation_steps to 4\")\n","    print(\"  3. Reduce MAX_LENGTH to 128\")\n","    success = False\n","\n","except Exception as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(f\"Error: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    success = False\n","\n","# 학습 시간 계산\n","duration = time.time() - start_time\n","duration_str = str(timedelta(seconds=int(duration)))\n","\n","# ============================================================================\n","# 10. 모델 저장 및 결과 정리\n","# ============================================================================\n","if success:\n","    print(f\"\\n{'='*70}\")\n","    print(\"Saving Model\")\n","    print(f\"{'='*70}\")\n","\n","    # 최종 모델 저장\n","    trainer.save_model(FINAL_DIR)\n","    tokenizer.save_pretrained(FINAL_DIR)\n","\n","    print(f\"✓ Model saved to: {FINAL_DIR}\")\n","\n","    # 학습 결과 요약\n","    summary = f\"\"\"\n","{'='*70}\n","mBART-50 Fine-tuning Results (NLLB-200 Configuration)\n","{'='*70}\n","\n","Dataset:\n","  - Train samples: {len(train_dataset):,}\n","  - Validation samples: {len(val_dataset):,}\n","\n","Model:\n","  - Name: {MODEL_NAME}\n","  - Parameters: {model.num_parameters():,}\n","\n","Configuration:\n","  - Epochs: 3\n","  - Batch size: 8\n","  - Gradient accumulation: 2\n","  - Effective batch size: 16\n","  - Learning rate: 1e-5\n","  - Warmup steps: 300\n","  - MAX_LENGTH: 256\n","  - FP16: Enabled\n","\n","Training:\n","  - Duration: {duration_str}\n","  - Final loss: {train_result.training_loss:.4f}\n","\n","Saved:\n","  - Location: {FINAL_DIR}\n","\n","{'='*70}\n","Training completed successfully!\n","{'='*70}\n","\"\"\"\n","\n","    print(summary)\n","\n","    # 요약 파일 저장\n","    with open(f\"{FINAL_DIR}/training_summary.txt\", 'w', encoding='utf-8') as f:\n","        f.write(summary)\n","\n","    print(f\"✓ Summary saved to: {FINAL_DIR}/training_summary.txt\")\n","\n","    # 학습 로그 저장\n","    if hasattr(trainer.state, 'log_history'):\n","        import json\n","        with open(f\"{FINAL_DIR}/training_logs.json\", 'w', encoding='utf-8') as f:\n","            json.dump(trainer.state.log_history, f, indent=2)\n","        print(f\"✓ Training logs saved to: {FINAL_DIR}/training_logs.json\")\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"SUCCESS! 🎉\")\n","    print(f\"{'='*70}\")\n","\n","else:\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING FAILED\")\n","    print(f\"{'='*70}\")\n","    print(f\"Duration: {duration_str}\")\n","    print(\"\\nPlease check the error messages above and try again.\")\n","\n","# ============================================================================\n","# 11. 메모리 정리\n","# ============================================================================\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"\\n✓ GPU memory cleared\")\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Script completed\")\n","print(f\"{'='*70}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":750},"id":"5Tuwd2l4IDy-","executionInfo":{"status":"error","timestamp":1762331246285,"user_tz":-540,"elapsed":30011,"user":{"displayName":"Ah-reum Lee","userId":"08227880159288094050"}},"outputId":"2153d9ad-ed8f-4d8b-9f0c-11d1b8356311"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","mBART-50 Fine-tuning (NLLB-200 Configuration)\n","======================================================================\n","\n","======================================================================\n","GPU Information\n","======================================================================\n","Device: cuda\n","GPU: NVIDIA A100-SXM4-40GB\n","Total Memory: 42.5 GB\n","✓ Colab Pro+ GPU detected!\n","\n","======================================================================\n","Mounting Google Drive\n","======================================================================\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Output directory: /content/drive/MyDrive/mbart_legal_nllb_config\n","\n","======================================================================\n","Upload Training Data\n","======================================================================\n","Please upload train_v2.csv and dev_v2.csv:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b20f4e48-69c2-4164-bf7b-27eed23be85a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b20f4e48-69c2-4164-bf7b-27eed23be85a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev_v2.csv to dev_v2 (1).csv\n","Saving train_v2.csv to train_v2 (1).csv\n","\n","✓ Uploaded files: ['dev_v2 (1).csv', 'train_v2 (1).csv']\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"train_v2.csv and dev_v2.csv are required!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3615332520.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# 데이터 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'train_v2.csv'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded_files\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'dev_v2.csv'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_v2.csv and dev_v2.csv are required!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_v2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: train_v2.csv and dev_v2.csv are required!"]}]},{"cell_type":"code","source":["\"\"\"\n","mBART-50 Fine-tuning with NLLB-200 Configuration\n","Optimized for Colab Pro+ (A100/V100)\n","\"\"\"\n","\n","# ============================================================================\n","# 1. 환경 설정 및 라이브러리 설치\n","# ============================================================================\n","print(\"=\"*70)\n","print(\"mBART-50 Fine-tuning (NLLB-200 Configuration)\")\n","print(\"=\"*70)\n","\n","!pip install transformers datasets sentencepiece accelerate -q\n","\n","import pandas as pd\n","import torch\n","from transformers import (\n","    MBartForConditionalGeneration,\n","    MBart50TokenizerFast,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from datasets import Dataset\n","from google.colab import files, drive\n","import time\n","from datetime import timedelta\n","import os\n","\n","# ============================================================================\n","# 2. GPU 확인\n","# ============================================================================\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"\\n{'='*70}\")\n","print(\"GPU Information\")\n","print(f\"{'='*70}\")\n","print(f\"Device: {device}\")\n","if device == \"cuda\":\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","    print(f\"GPU: {gpu_name}\")\n","    print(f\"Total Memory: {gpu_memory:.1f} GB\")\n","\n","    # Colab Pro+ 확인\n","    if \"A100\" in gpu_name or \"V100\" in gpu_name:\n","        print(\"✓ Colab Pro+ GPU detected!\")\n","    else:\n","        print(\"⚠ Warning: This configuration requires Colab Pro+ (A100/V100)\")\n","\n","# ============================================================================\n","# 3. Google Drive 마운트\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Mounting Google Drive\")\n","print(f\"{'='*70}\")\n","drive.mount('/content/drive')\n","\n","# 저장 경로 설정\n","OUTPUT_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_config\"\n","FINAL_DIR = \"/content/drive/MyDrive/mbart_legal_nllb_final\"\n","\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","print(f\"✓ Output directory: {OUTPUT_DIR}\")\n","\n","# ============================================================================\n","# 4. 데이터 파일 업로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Upload Training Data\")\n","print(f\"{'='*70}\")\n","print(\"Please upload train_v2.csv and dev_v2.csv:\")\n","\n","uploaded = files.upload()\n","\n","# 업로드된 파일 확인\n","uploaded_files = list(uploaded.keys())\n","print(f\"\\n✓ Uploaded files: {uploaded_files}\")\n","\n","# 정확한 파일명 체크\n","if 'train_v2.csv' not in uploaded_files:\n","    print(\"\\n❌ Error: 'train_v2.csv' not found!\")\n","    print(f\"Available files: {uploaded_files}\")\n","    raise FileNotFoundError(\"Please upload train_v2.csv\")\n","\n","if 'dev_v2.csv' not in uploaded_files:\n","    print(\"\\n❌ Error: 'dev_v2.csv' not found!\")\n","    print(f\"Available files: {uploaded_files}\")\n","    raise FileNotFoundError(\"Please upload dev_v2.csv\")\n","\n","print(\"✓ train_v2.csv found\")\n","print(\"✓ dev_v2.csv found\")\n","\n","# 데이터 로드\n","train_df = pd.read_csv('train_v2.csv')\n","val_df = pd.read_csv('dev_v2.csv')\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Dataset Information\")\n","print(f\"{'='*70}\")\n","print(f\"Train samples: {len(train_df):,}\")\n","print(f\"Validation samples: {len(val_df):,}\")\n","print(f\"\\nSample data:\")\n","print(train_df.head(2))\n","\n","# ============================================================================\n","# 5. 모델 및 토크나이저 로드\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Loading Model and Tokenizer\")\n","print(f\"{'='*70}\")\n","\n","MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n","print(f\"Model: {MODEL_NAME}\")\n","\n","tokenizer = MBart50TokenizerFast.from_pretrained(\n","    MODEL_NAME,\n","    src_lang=\"ru_RU\",\n","    tgt_lang=\"ko_KR\"\n",")\n","print(\"✓ Tokenizer loaded\")\n","\n","model = MBartForConditionalGeneration.from_pretrained(MODEL_NAME)\n","print(f\"✓ Model loaded: {model.num_parameters():,} parameters\")\n","\n","# ============================================================================\n","# 6. 데이터 전처리 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Data Preprocessing (NLLB-200 Config)\")\n","print(f\"{'='*70}\")\n","\n","# NLLB-200 설정값\n","MAX_LENGTH = 256  # 최대 시퀀스 길이\n","\n","def preprocess_function(examples):\n","    \"\"\"NLLB-200 방식의 전처리\"\"\"\n","    tokenizer.src_lang = \"ru_RU\"\n","\n","    # Source 언어 토크나이징\n","    inputs = tokenizer(\n","        examples['ru'],\n","        max_length=MAX_LENGTH,\n","        truncation=True,\n","        padding=False\n","    )\n","\n","    # Target 언어 토크나이징\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples['ko'],\n","            max_length=MAX_LENGTH,\n","            truncation=True,\n","            padding=False\n","        )\n","\n","    inputs['labels'] = labels['input_ids']\n","    return inputs\n","\n","# 데이터셋 변환\n","train_dataset = Dataset.from_pandas(train_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=train_df.columns.tolist()\n",")\n","\n","val_dataset = Dataset.from_pandas(val_df).map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=val_df.columns.tolist()\n",")\n","\n","# Data Collator\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer,\n","    model=model,\n","    padding=True\n",")\n","\n","print(f\"✓ Train dataset: {len(train_dataset):,} samples\")\n","print(f\"✓ Validation dataset: {len(val_dataset):,} samples\")\n","print(f\"✓ MAX_LENGTH: {MAX_LENGTH}\")\n","\n","# ============================================================================\n","# 7. 학습 설정 (NLLB-200 Configuration)\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Training Configuration (NLLB-200 Settings)\")\n","print(f\"{'='*70}\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    # 기본 설정\n","    output_dir=OUTPUT_DIR,\n","\n","    # 학습 설정\n","    num_train_epochs=3,                      # 에포크 수\n","    per_device_train_batch_size=8,           # 배치 크기 (GPU 당)\n","    gradient_accumulation_steps=2,           # 그래디언트 누적 (실질 배치 16)\n","\n","    # 학습률 및 최적화\n","    learning_rate=1e-5,                      # 학습률 (1×10⁻⁵)\n","    warmup_steps=300,                        # 워밍업 단계\n","\n","    # 로깅 및 저장\n","    logging_steps=100,                       # 로그 기록 간격\n","    save_steps=500,                          # 모델 저장 간격\n","    eval_steps=500,                          # 검증 실행 간격\n","\n","    # 저장 전략\n","    save_strategy=\"steps\",\n","    eval_strategy=\"steps\",\n","    save_total_limit=3,                      # 최대 체크포인트 수\n","\n","    # 메모리 최적화\n","    fp16=True,                               # FP16 혼합 정밀도\n","\n","    # 기타\n","    report_to=\"none\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n","    greater_is_better=False,\n","    predict_with_generate=False,             # 평가 시 생성 비활성화 (속도 향상)\n",")\n","\n","print(f\"\"\"\n","Configuration Summary:\n","{'='*70}\n","Model: {MODEL_NAME}\n","Epochs: 3\n","Batch size per device: 8\n","Gradient accumulation: 2\n","Effective batch size: 16\n","Learning rate: 1e-5\n","Warmup steps: 300\n","MAX_LENGTH: 256\n","FP16: Enabled\n","{'='*70}\n","\"\"\")\n","\n","# ============================================================================\n","# 8. Trainer 초기화\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"Initializing Trainer\")\n","print(f\"{'='*70}\")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","print(\"✓ Trainer initialized\")\n","\n","# GPU 캐시 정리\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"✓ GPU cache cleared\")\n","\n","# ============================================================================\n","# 9. 학습 실행\n","# ============================================================================\n","print(f\"\\n{'='*70}\")\n","print(\"TRAINING START\")\n","print(f\"{'='*70}\")\n","\n","start_time = time.time()\n","print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","\n","try:\n","    # 학습 시작\n","    train_result = trainer.train()\n","\n","    # 학습 완료\n","    success = True\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING COMPLETED!\")\n","    print(f\"{'='*70}\")\n","\n","except torch.cuda.OutOfMemoryError as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"OOM ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(\"Out of memory error occurred.\")\n","    print(\"\\nOptions:\")\n","    print(\"  1. Reduce batch_size to 4\")\n","    print(\"  2. Increase gradient_accumulation_steps to 4\")\n","    print(\"  3. Reduce MAX_LENGTH to 128\")\n","    success = False\n","\n","except Exception as e:\n","    print(f\"\\n{'='*70}\")\n","    print(\"ERROR!\")\n","    print(f\"{'='*70}\")\n","    print(f\"Error: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    success = False\n","\n","# 학습 시간 계산\n","duration = time.time() - start_time\n","duration_str = str(timedelta(seconds=int(duration)))\n","\n","# ============================================================================\n","# 10. 모델 저장 및 결과 정리\n","# ============================================================================\n","if success:\n","    print(f\"\\n{'='*70}\")\n","    print(\"Saving Model\")\n","    print(f\"{'='*70}\")\n","\n","    # 최종 모델 저장\n","    trainer.save_model(FINAL_DIR)\n","    tokenizer.save_pretrained(FINAL_DIR)\n","\n","    print(f\"✓ Model saved to: {FINAL_DIR}\")\n","\n","    # 학습 결과 요약\n","    summary = f\"\"\"\n","{'='*70}\n","mBART-50 Fine-tuning Results (NLLB-200 Configuration)\n","{'='*70}\n","\n","Dataset:\n","  - Train samples: {len(train_dataset):,}\n","  - Validation samples: {len(val_dataset):,}\n","\n","Model:\n","  - Name: {MODEL_NAME}\n","  - Parameters: {model.num_parameters():,}\n","\n","Configuration:\n","  - Epochs: 3\n","  - Batch size: 8\n","  - Gradient accumulation: 2\n","  - Effective batch size: 16\n","  - Learning rate: 1e-5\n","  - Warmup steps: 300\n","  - MAX_LENGTH: 256\n","  - FP16: Enabled\n","\n","Training:\n","  - Duration: {duration_str}\n","  - Final loss: {train_result.training_loss:.4f}\n","\n","Saved:\n","  - Location: {FINAL_DIR}\n","\n","{'='*70}\n","Training completed successfully!\n","{'='*70}\n","\"\"\"\n","\n","    print(summary)\n","\n","    # 요약 파일 저장\n","    with open(f\"{FINAL_DIR}/training_summary.txt\", 'w', encoding='utf-8') as f:\n","        f.write(summary)\n","\n","    print(f\"✓ Summary saved to: {FINAL_DIR}/training_summary.txt\")\n","\n","    # 학습 로그 저장\n","    if hasattr(trainer.state, 'log_history'):\n","        import json\n","        with open(f\"{FINAL_DIR}/training_logs.json\", 'w', encoding='utf-8') as f:\n","            json.dump(trainer.state.log_history, f, indent=2)\n","        print(f\"✓ Training logs saved to: {FINAL_DIR}/training_logs.json\")\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"SUCCESS! 🎉\")\n","    print(f\"{'='*70}\")\n","\n","else:\n","    print(f\"\\n{'='*70}\")\n","    print(\"TRAINING FAILED\")\n","    print(f\"{'='*70}\")\n","    print(f\"Duration: {duration_str}\")\n","    print(\"\\nPlease check the error messages above and try again.\")\n","\n","# ============================================================================\n","# 11. 메모리 정리\n","# ============================================================================\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    print(\"\\n✓ GPU memory cleared\")\n","\n","print(f\"\\n{'='*70}\")\n","print(\"Script completed\")\n","print(f\"{'='*70}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2c4a34ecf1d14729995bef3b57b3ec9c","54c0c759e476463ba73fb279665169c2","d501632bc0324c61b22b77c22fd42d96","291e3587e9eb4e40a8557cbc2bf5f8d7","186cee8223d24461b26380f35b26ec4c","0325f6ea8a24438e9cbd7eee60f4f0ea","75743a710309493f94808e2779d86a4b","8259d36fac384ca4a1f4aa7f2498c3e5","f286567bceaf4bd0ad8589b4278df7b5","920e5cedcb874399af3cb023bcce9924","df4c37d4759c4c648f532b63210c5a6e","ec9b39331cb94a0e9d2a974be0ce12fb","6a801c9a66834f1eb3d69cbc8239ef3b","a19b4c564394455b8577261aaac77ec2","7c8ad6d685d346a8845e8c0de8482885","77a088f73c6640f3bd08c63d60b86d45","624aabd0de644db9a737eb464fdedf1d","6348691909844dc9a185f6194438e8e6","cc39b50cbb734ffea5d68a16522e9e46","371e4a18f88447fb9ee33878519ca155","3326f991ff0f4bfab59b29fa2d49ef09","a01259bbbb6c460583b7bf9c85c3c41c"]},"id":"dn4ZA91hI_AC","executionInfo":{"status":"ok","timestamp":1762332068350,"user_tz":-540,"elapsed":609607,"user":{"displayName":"Ah-reum Lee","userId":"08227880159288094050"}},"outputId":"971c7e66-9503-44e9-e084-f356729fcd49"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","mBART-50 Fine-tuning (NLLB-200 Configuration)\n","======================================================================\n","\n","======================================================================\n","GPU Information\n","======================================================================\n","Device: cuda\n","GPU: NVIDIA A100-SXM4-40GB\n","Total Memory: 42.5 GB\n","✓ Colab Pro+ GPU detected!\n","\n","======================================================================\n","Mounting Google Drive\n","======================================================================\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✓ Output directory: /content/drive/MyDrive/mbart_legal_nllb_config\n","\n","======================================================================\n","Upload Training Data\n","======================================================================\n","Please upload train_v2.csv and dev_v2.csv:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6af0b88f-b9a5-4aa0-bb7d-cd88cbb9cb25\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6af0b88f-b9a5-4aa0-bb7d-cd88cbb9cb25\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev_v2.csv to dev_v2.csv\n","Saving train_v2.csv to train_v2.csv\n","\n","✓ Uploaded files: ['dev_v2.csv', 'train_v2.csv']\n","✓ train_v2.csv found\n","✓ dev_v2.csv found\n","\n","======================================================================\n","Dataset Information\n","======================================================================\n","Train samples: 8,000\n","Validation samples: 1,000\n","\n","Sample data:\n","   id                                                 ru  \\\n","0   1  Российская Федерация - Россия есть демократиче...   \n","1   2  Наименования Российская Федерация и Россия рав...   \n","\n","                                             ko  \n","0  러시아연방, 즉 러시아는 공화국 통치 형태를 갖춘 민주주의 연방 법치 국가이다.  \n","1                 러시아연방과 러시아라는 명칭은 동일한 의미를 지닌다.  \n","\n","======================================================================\n","Loading Model and Tokenizer\n","======================================================================\n","Model: facebook/mbart-large-50-many-to-many-mmt\n","✓ Tokenizer loaded\n","✓ Model loaded: 610,879,488 parameters\n","\n","======================================================================\n","Data Preprocessing (NLLB-200 Config)\n","======================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4a34ecf1d14729995bef3b57b3ec9c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9b39331cb94a0e9d2a974be0ce12fb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Train dataset: 8,000 samples\n","✓ Validation dataset: 1,000 samples\n","✓ MAX_LENGTH: 256\n","\n","======================================================================\n","Training Configuration (NLLB-200 Settings)\n","======================================================================\n","\n","Configuration Summary:\n","======================================================================\n","Model: facebook/mbart-large-50-many-to-many-mmt\n","Epochs: 3\n","Batch size per device: 8\n","Gradient accumulation: 2\n","Effective batch size: 16\n","Learning rate: 1e-5\n","Warmup steps: 300\n","MAX_LENGTH: 256\n","FP16: Enabled\n","======================================================================\n","\n","\n","======================================================================\n","Initializing Trainer\n","======================================================================\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3806099576.py:246: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n"]},{"output_type":"stream","name":"stdout","text":["✓ Trainer initialized\n","✓ GPU cache cleared\n","\n","======================================================================\n","TRAINING START\n","======================================================================\n","Start time: 2025-11-05 08:31:31\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1500/1500 08:58, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.383500</td>\n","      <td>1.261342</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.103500</td>\n","      <td>1.091912</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.951800</td>\n","      <td>1.059713</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","TRAINING COMPLETED!\n","======================================================================\n","\n","======================================================================\n","Saving Model\n","======================================================================\n","✓ Model saved to: /content/drive/MyDrive/mbart_legal_nllb_final\n","\n","======================================================================\n","mBART-50 Fine-tuning Results (NLLB-200 Configuration)\n","======================================================================\n","\n","Dataset:\n","  - Train samples: 8,000\n","  - Validation samples: 1,000\n","\n","Model:\n","  - Name: facebook/mbart-large-50-many-to-many-mmt\n","  - Parameters: 610,879,488\n","\n","Configuration:\n","  - Epochs: 3\n","  - Batch size: 8\n","  - Gradient accumulation: 2\n","  - Effective batch size: 16\n","  - Learning rate: 1e-5\n","  - Warmup steps: 300\n","  - MAX_LENGTH: 256\n","  - FP16: Enabled\n","\n","Training:\n","  - Duration: 0:09:00\n","  - Final loss: 1.3560\n","\n","Saved:\n","  - Location: /content/drive/MyDrive/mbart_legal_nllb_final\n","\n","======================================================================\n","Training completed successfully!\n","======================================================================\n","\n","✓ Summary saved to: /content/drive/MyDrive/mbart_legal_nllb_final/training_summary.txt\n","✓ Training logs saved to: /content/drive/MyDrive/mbart_legal_nllb_final/training_logs.json\n","\n","======================================================================\n","SUCCESS! 🎉\n","======================================================================\n","\n","✓ GPU memory cleared\n","\n","======================================================================\n","Script completed\n","======================================================================\n"]}]}]}