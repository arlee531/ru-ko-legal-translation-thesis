"""
ë‹´í™”í‘œì§€ 5ë²”ì£¼ ë¶„í¬ ë¶„ì„ ì½”ë“œ
ëŸ¬-í•œ ë²•ë¥  ì½”í¼ìŠ¤ì—ì„œ ë‹´í™”í‘œì§€ ë²”ì£¼ë³„ ë¶„í¬ ë¶„ì„

import pandas as pd
import re
from collections import defaultdict

# 1. íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ë¡œë”© (ì½”ë©ì—ì„œ ì‹¤í–‰)
print("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”...")
from google.colab import files
uploaded = files.upload()

# ì—…ë¡œë“œëœ íŒŒì¼ëª… í™•ì¸
filename = list(uploaded.keys())[0]
print(f"ì—…ë¡œë“œëœ íŒŒì¼: {filename}")

# CSV íŒŒì¼ ë¡œë”©
df = pd.read_csv(filename)
print(f"ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ë¬¸ì¥")
print(f"ì»¬ëŸ¼: {list(df.columns)}")
print(f"ì²« 3ê°œ ìƒ˜í”Œ:")
print(df.head(3))

# 2. í‘œ 17 ê¸°ì¤€ ë‹´í™” í‘œì§€ ì‚¬ì „ ì •ì˜
discourse_markers = {
    "ì ‘ì† í‘œì§€": {
        "ru": ["Ğ¸", "Ğ¸Ğ»Ğ¸", "Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ", "Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ", "ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ³Ğ¾", "Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ", "Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼"],
        "ko": ["ë°", "ë˜ëŠ”", "ê·¸ë¦¬ê³ ", "ë”°ë¼ì„œ", "ë˜í•œ", "ì•„ìš¸ëŸ¬", "í˜¹ì€"]
    },
    "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€": {
        "ru": ["ĞµÑĞ»Ğ¸", "Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾", "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼", "Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ°", "Ñ…Ğ¾Ñ‚Ñ", "Ğ½Ğ¾", "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²", "Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ", "ĞµÑĞ»Ğ¸", "Ğ¿Ñ€Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¸"],
        "ko": ["ë‹¤ë§Œ", "ë‹¨", "ë§Œì•½", "ê²½ìš°", "ê·¸ëŸ¬ë‚˜", "ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ë¹„ë¡", "í• ì§€ë¼ë„", "ì´ ê²½ìš°", "ì´ë•Œ", "í•˜ëŠ”/í•œ/í•  ê²½ìš°"]
    },
    "ê·¼ê±°/ì§€ì‹œ í‘œì§€": {
        "ru": ["Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ", "ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾", "Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ/Ğ² ÑĞ»ÑƒÑ‡Ğ°ÑÑ…", "Ğ² Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¸", "Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸"],
        "ko": ["ì— ë”°ë¼", "ì— ì˜í•˜ì—¬", "ì— ê´€í•˜ì—¬", "ì— ëŒ€í•œ", "ì— ì˜ê±°í•˜ì—¬", "ì— ê·¼ê±°í•˜ì—¬"]
    },
    "ê·œë²” ì–‘ìƒ í‘œì§€": {
        "ru": ["Ğ¼Ğ¾Ğ¶ĞµÑ‚", "Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½", "Ğ²Ğ¿Ñ€Ğ°Ğ²Ğµ", "Ğ¾Ğ±ÑĞ·Ğ°Ğ½", "Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ÑÑ", "ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚", "Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ¸Ñ‚/Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ°Ñ‚"],
        "ko": ["í•  ìˆ˜ ìˆë‹¤/ìˆ˜ ì—†ë‹¤", "í•´ì•¼ í•œë‹¤", "í•˜ì§€ ì•„ë‹ˆí•œë‹¤", "ì •í•œë‹¤", "ê·œì •í•œë‹¤", "ê¸ˆì§€í•œë‹¤", "ì–»ëŠ”ë‹¤"]
    },
    "ì°¸ì¡° í‘œì§€": {
        "ru": ["ÑÑ‚Ğ°Ñ‚ÑŒÑ/ÑÑ‚Ğ°Ñ‚ÑŒĞ¸", "Ğ¿ÑƒĞ½ĞºÑ‚", "Ğ¿Ğ¾Ğ´Ğ¿ÑƒĞ½ĞºÑ‚", "Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹", "ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹", "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹", "ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹", "Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹", "Ğ²Ñ‹ÑˆĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹/Ğ½Ğ¸Ğ¶ĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹"],
        "ko": ["ì œ N ì¥", "ì œ N ì¡°", "ì œ N í•­", "ì œ N ëª©", "ì œ N í˜¸", "í•´ë‹¹", "ìƒê¸°", "ë³¸ í•­", "ë³¸ ì¡°", "ë³¸ ë²•", "ë™", "ê°™ì€", "ì´ ë²•", "ì´ ì¡°", "ì´ í•­"]
    }
}

# 3. ì •ê·œì‹ íŒ¨í„´ ì •ì˜ (í‘œ 17ì˜ ì‹¤ì œ í‘œí˜„ ê¸°ì¤€)
patterns = {
    "ru": {
        # ì ‘ì† í‘œì§€
        "Ğ¸": r'\bĞ¸\b',
        "Ğ¸Ğ»Ğ¸": r'\bĞ¸Ğ»Ğ¸\b', 
        "Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ": r'Ğ°\s+Ñ‚Ğ°ĞºĞ¶Ğµ',
        "Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ": r'\bĞ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ\b',
        "ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ³Ğ¾": r'ĞºÑ€Ğ¾Ğ¼Ğµ\s+Ñ‚Ğ¾Ğ³Ğ¾',
        "Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ": r'Ğ²\s+Ñ‚Ğ¾Ğ¼\s+Ñ‡Ğ¸ÑĞ»Ğµ',
        "Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼": r'Ğ¿Ñ€Ğ¸\s+ÑÑ‚Ğ¾Ğ¼',
        
        # ì¡°ê±´/ëŒ€ë¦½ í‘œì§€  
        "ĞµÑĞ»Ğ¸": r'\bĞµÑĞ»Ğ¸\b',
        "Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾": r'\bĞ¾Ğ´Ğ½Ğ°ĞºĞ¾\b',
        "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼": r'Ğ·Ğ°\s+Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼',
        "Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ°": r'Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ\s+Ğ½Ğ°',
        "Ñ…Ğ¾Ñ‚Ñ": r'\bÑ…Ğ¾Ñ‚Ñ\b',
        "Ğ½Ğ¾": r'\bĞ½Ğ¾\b',
        "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²": r'Ğ·Ğ°\s+Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼\s+ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²',
        "Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ": r'Ğ²\s+ÑĞ»ÑƒÑ‡Ğ°Ğµ',
        "Ğ¿Ñ€Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¸": r'Ğ¿Ñ€Ğ¸\s+ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¸',
        
        # ê·¼ê±°/ì§€ì‹œ í‘œì§€
        "Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ": r'Ğ²\s+ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸\s+Ñ',
        "ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾": r'\bÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾\b',
        "Ğ² ÑĞ»ÑƒÑ‡Ğ°ÑÑ…": r'Ğ²\s+ÑĞ»ÑƒÑ‡Ğ°ÑÑ…', 
        "Ğ² Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¸": r'Ğ²\s+Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¸',
        "Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸": r'Ğ½Ğ°\s+Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸',
        
        # ê·œë²” ì–‘ìƒ í‘œì§€
        "Ğ¼Ğ¾Ğ¶ĞµÑ‚": r'\bĞ¼Ğ¾Ğ¶ĞµÑ‚\b',
        "Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½": r'Ğ´Ğ¾Ğ»Ğ¶Ğ½[Ğ°-Ñ]+',
        "Ğ²Ğ¿Ñ€Ğ°Ğ²Ğµ": r'\bĞ²Ğ¿Ñ€Ğ°Ğ²Ğµ\b',
        "Ğ¾Ğ±ÑĞ·Ğ°Ğ½": r'Ğ¾Ğ±ÑĞ·Ğ°Ğ½[Ğ°-Ñ]*',
        "Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ÑÑ": r'\bĞ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ÑÑ\b',
        "ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚": r'\bÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚\b',
        "Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ¸Ñ‚": r'\bĞ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ¸Ñ‚\b',
        "Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ°Ñ‚": r'\bĞ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ°Ñ‚\b',
        
        # ì°¸ì¡° í‘œì§€
        "ÑÑ‚Ğ°Ñ‚ÑŒÑ": r'\bÑÑ‚Ğ°Ñ‚ÑŒÑ\b',
        "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸": r'\bÑÑ‚Ğ°Ñ‚ÑŒĞ¸\b',
        "Ğ¿ÑƒĞ½ĞºÑ‚": r'Ğ¿ÑƒĞ½ĞºÑ‚[Ğ°-Ñ]*',
        "Ğ¿Ğ¾Ğ´Ğ¿ÑƒĞ½ĞºÑ‚": r'Ğ¿Ğ¾Ğ´Ğ¿ÑƒĞ½ĞºÑ‚[Ğ°-Ñ]*',
        "Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹": r'Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰[Ğ°-Ñ]+',
        "ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": r'ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½[Ğ°-Ñ]+',
        "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹": r'Ğ´Ğ°Ğ½Ğ½[Ğ°-Ñ]+',
        "ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹": r'ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰[Ğ°-Ñ]+',
        "Ğ²Ñ‹ÑˆĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": r'Ğ²Ñ‹ÑˆĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½[Ğ°-Ñ]+',
        "Ğ½Ğ¸Ğ¶ĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": r'Ğ½Ğ¸Ğ¶ĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½[Ğ°-Ñ]+'
    },
    
    "ko": {
        # ì ‘ì† í‘œì§€
        "ë°": r'\bë°\b',
        "ë˜ëŠ”": r'\bë˜ëŠ”\b',
        "ê·¸ë¦¬ê³ ": r'\bê·¸ë¦¬ê³ \b', 
        "ë”°ë¼ì„œ": r'\bë”°ë¼ì„œ\b',
        "ë˜í•œ": r'\bë˜í•œ\b',
        "ì•„ìš¸ëŸ¬": r'\bì•„ìš¸ëŸ¬\b',
        "í˜¹ì€": r'\bí˜¹ì€\b',
        
        # ì¡°ê±´/ëŒ€ë¦½ í‘œì§€
        "ë‹¤ë§Œ": r'\bë‹¤ë§Œ\b',
        "ë‹¨": r'\bë‹¨[\s,]',
        "ë§Œì•½": r'\bë§Œì•½\b',
        "ê²½ìš°": r'\bê²½ìš°\b',
        "ê·¸ëŸ¬ë‚˜": r'\bê·¸ëŸ¬ë‚˜ë‚˜\b',
        "ê·¸ëŸ°ë°": r'\bê·¸ëŸ°ë°\b', 
        "í•˜ì§€ë§Œ": r'\bí•˜ì§€ë§Œ\b',
        "ë¹„ë¡": r'\bë¹„ë¡\b',
        "í• ì§€ë¼ë„": r'\bí• ì§€ë¼ë„\b',
        "ì´ ê²½ìš°": r'ì´\s*ê²½ìš°',
        "ì´ë•Œ": r'\bì´ë•Œ\b',
        "í•˜ëŠ” ê²½ìš°": r'í•˜ëŠ”\s*ê²½ìš°',
        "í•œ ê²½ìš°": r'í•œ\s*ê²½ìš°',
        "í•  ê²½ìš°": r'í• \s*ê²½ìš°',
        
        # ê·¼ê±°/ì§€ì‹œ í‘œì§€
        "ì— ë”°ë¼": r'ì—\s*ë”°ë¼',
        "ì— ì˜í•˜ì—¬": r'ì—\s*ì˜í•˜ì—¬',
        "ì— ê´€í•˜ì—¬": r'ì—\s*ê´€í•˜ì—¬',
        "ì— ëŒ€í•œ": r'ì—\s*ëŒ€í•œ',
        "ì— ì˜ê±°í•˜ì—¬": r'ì—\s*ì˜ê±°í•˜ì—¬',
        "ì— ê·¼ê±°í•˜ì—¬": r'ì—\s*ê·¼ê±°í•˜ì—¬',
        
        # ê·œë²” ì–‘ìƒ í‘œì§€
        "í•  ìˆ˜ ìˆë‹¤": r'í• \s*ìˆ˜\s*ìˆë‹¤',
        "ìˆ˜ ì—†ë‹¤": r'ìˆ˜\s*ì—†ë‹¤',
        "í•´ì•¼ í•œë‹¤": r'í•´ì•¼\s*í•œë‹¤',
        "í•˜ì§€ ì•„ë‹ˆí•œë‹¤": r'í•˜ì§€\s*ì•„ë‹ˆí•œë‹¤',
        "ì •í•œë‹¤": r'ì •í•œë‹¤',
        "ê·œì •í•œë‹¤": r'ê·œì •í•œë‹¤',
        "ê¸ˆì§€í•œë‹¤": r'ê¸ˆì§€í•œë‹¤',
        "ì–»ëŠ”ë‹¤": r'ì–»ëŠ”ë‹¤',
        
        # ì°¸ì¡° í‘œì§€
        "ì œ": r'ì œ\s*\d+',
        "ì¡°": r'\d+\s*ì¡°',
        "í•­": r'\d+\s*í•­',
        "ëª©": r'\d+\s*ëª©',
        "í˜¸": r'\d+\s*í˜¸',
        "í•´ë‹¹": r'\bí•´ë‹¹\b',
        "ìƒê¸°": r'\bìƒê¸°\b',
        "ë³¸ í•­": r'ë³¸\s*í•­',
        "ë³¸ ì¡°": r'ë³¸\s*ì¡°',
        "ë³¸ ë²•": r'ë³¸\s*ë²•',
        "ë™": r'ë™\s*[ì¡°í•­ëª©í˜¸]',
        "ê°™ì€": r'\bê°™ì€\b',
        "ì´ ë²•": r'ì´\s*ë²•',
        "ì´ ì¡°": r'ì´\s*ì¡°',
        "ì´ í•­": r'ì´\s*í•­'
    }
}

# 4. ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
ru_text = ' '.join(df['ru'].fillna('').astype(str))
ko_text = ' '.join(df['ko'].fillna('').astype(str))

print(f"ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ru_text):,}ì")
print(f"í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ko_text):,}ì")

# 5. ë¹ˆë„ ë¶„ì„ í•¨ìˆ˜
def analyze_markers(text, patterns_dict, language):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‹´í™” í‘œì§€ ë¹ˆë„ ë¶„ì„"""
    results = {}
    
    for marker, pattern in patterns_dict[language].items():
        matches = re.findall(pattern, text, re.IGNORECASE)
        results[marker] = len(matches)
    
    return results

# 6. ë¶„ì„ ì‹¤í–‰
print("\n" + "="*80)
print("ë‹´í™” í‘œì§€ ë¹ˆë„ ë¶„ì„ ì‹œì‘...")
print("="*80)

ru_frequency = analyze_markers(ru_text, patterns, 'ru')
ko_frequency = analyze_markers(ko_text, patterns, 'ko')

# 7. ë²”ì£¼ë³„ ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
category_mapping = {
    # ì ‘ì† í‘œì§€
    "Ğ¸": "ì ‘ì† í‘œì§€", "Ğ¸Ğ»Ğ¸": "ì ‘ì† í‘œì§€", "Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ": "ì ‘ì† í‘œì§€",
    "Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ": "ì ‘ì† í‘œì§€", "ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ³Ğ¾": "ì ‘ì† í‘œì§€", "Ğ² Ñ‚Ğ¾Ğ¼ Ñ‡Ğ¸ÑĞ»Ğµ": "ì ‘ì† í‘œì§€", "Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼": "ì ‘ì† í‘œì§€",
    "ë°": "ì ‘ì† í‘œì§€", "ë˜ëŠ”": "ì ‘ì† í‘œì§€", "ê·¸ë¦¬ê³ ": "ì ‘ì† í‘œì§€",
    "ë”°ë¼ì„œ": "ì ‘ì† í‘œì§€", "ë˜í•œ": "ì ‘ì† í‘œì§€", "ì•„ìš¸ëŸ¬": "ì ‘ì† í‘œì§€", "í˜¹ì€": "ì ‘ì† í‘œì§€",
    
    # ì¡°ê±´/ëŒ€ë¦½ í‘œì§€
    "ĞµÑĞ»Ğ¸": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", 
    "Ñ…Ğ¾Ñ‚Ñ": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ½Ğ¾": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ·Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "Ğ¿Ñ€Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¸": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€",
    "ë‹¤ë§Œ": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ë‹¨": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ë§Œì•½": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê²½ìš°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¸ëŸ¬ë‚˜": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¸ëŸ°ë°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€",
    "í•˜ì§€ë§Œ": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ë¹„ë¡": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "í• ì§€ë¼ë„": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ì´ ê²½ìš°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", 
    "ì´ë•Œ": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "í•˜ëŠ” ê²½ìš°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "í•œ ê²½ìš°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "í•  ê²½ìš°": "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€",
    
    # ê·¼ê±°/ì§€ì‹œ í‘œì§€
    "Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ÑĞ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "Ğ² ÑĞ»ÑƒÑ‡Ğ°ÑÑ…": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", 
    "Ğ² Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¸": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸": "ê·¼ê±°/ì§€ì‹œ í‘œì§€",
    "ì— ë”°ë¼": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ì— ì˜í•˜ì—¬": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ì— ê´€í•˜ì—¬": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", 
    "ì— ëŒ€í•œ": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ì— ì˜ê±°í•˜ì—¬": "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ì— ê·¼ê±°í•˜ì—¬": "ê·¼ê±°/ì§€ì‹œ í‘œì§€",
    
    # ê·œë²” ì–‘ìƒ í‘œì§€
    "Ğ¼Ğ¾Ğ¶ĞµÑ‚": "ê·œë²” ì–‘ìƒ í‘œì§€", "Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½": "ê·œë²” ì–‘ìƒ í‘œì§€", "Ğ²Ğ¿Ñ€Ğ°Ğ²Ğµ": "ê·œë²” ì–‘ìƒ í‘œì§€", "Ğ¾Ğ±ÑĞ·Ğ°Ğ½": "ê·œë²” ì–‘ìƒ í‘œì§€",
    "Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ğ°ĞµÑ‚ÑÑ": "ê·œë²” ì–‘ìƒ í‘œì§€", "ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚": "ê·œë²” ì–‘ìƒ í‘œì§€", "Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ¸Ñ‚": "ê·œë²” ì–‘ìƒ í‘œì§€", "Ğ¿Ğ¾Ğ´Ğ»ĞµĞ¶Ğ°Ñ‚": "ê·œë²” ì–‘ìƒ í‘œì§€",
    "í•  ìˆ˜ ìˆë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", "ìˆ˜ ì—†ë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", "í•´ì•¼ í•œë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", 
    "í•˜ì§€ ì•„ë‹ˆí•œë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", "ì •í•œë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", "ê·œì •í•œë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", 
    "ê¸ˆì§€í•œë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€", "ì–»ëŠ”ë‹¤": "ê·œë²” ì–‘ìƒ í‘œì§€",
    
    # ì°¸ì¡° í‘œì§€
    "ÑÑ‚Ğ°Ñ‚ÑŒÑ": "ì°¸ì¡° í‘œì§€", "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸": "ì°¸ì¡° í‘œì§€", "Ğ¿ÑƒĞ½ĞºÑ‚": "ì°¸ì¡° í‘œì§€", "Ğ¿Ğ¾Ğ´Ğ¿ÑƒĞ½ĞºÑ‚": "ì°¸ì¡° í‘œì§€",
    "Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹": "ì°¸ì¡° í‘œì§€", "ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": "ì°¸ì¡° í‘œì§€", "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹": "ì°¸ì¡° í‘œì§€", "ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹": "ì°¸ì¡° í‘œì§€",
    "Ğ²Ñ‹ÑˆĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": "ì°¸ì¡° í‘œì§€", "Ğ½Ğ¸Ğ¶ĞµÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğ¹": "ì°¸ì¡° í‘œì§€",
    "ì œ": "ì°¸ì¡° í‘œì§€", "ì¡°": "ì°¸ì¡° í‘œì§€", "í•­": "ì°¸ì¡° í‘œì§€", "ëª©": "ì°¸ì¡° í‘œì§€", "í˜¸": "ì°¸ì¡° í‘œì§€",
    "í•´ë‹¹": "ì°¸ì¡° í‘œì§€", "ìƒê¸°": "ì°¸ì¡° í‘œì§€", "ë³¸ í•­": "ì°¸ì¡° í‘œì§€", "ë³¸ ì¡°": "ì°¸ì¡° í‘œì§€", "ë³¸ ë²•": "ì°¸ì¡° í‘œì§€",
    "ë™": "ì°¸ì¡° í‘œì§€", "ê°™ì€": "ì°¸ì¡° í‘œì§€", "ì´ ë²•": "ì°¸ì¡° í‘œì§€", "ì´ ì¡°": "ì°¸ì¡° í‘œì§€", "ì´ í•­": "ì°¸ì¡° í‘œì§€"
}

# 8. ë²”ì£¼ë³„ í†µê³„ ê³„ì‚°
category_stats = defaultdict(lambda: {"ru": defaultdict(int), "ko": defaultdict(int)})

for marker, count in ru_frequency.items():
    if marker in category_mapping:
        category = category_mapping[marker]
        category_stats[category]["ru"][marker] = count

for marker, count in ko_frequency.items():
    if marker in category_mapping:
        category = category_mapping[marker]
        category_stats[category]["ko"][marker] = count

# 9. ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š ë‹´í™” í‘œì§€ ë²”ì£¼ë³„ ë¶„ì„ ê²°ê³¼")
print("="*80)

for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    print(f"\nğŸ”¹ {category}")
    print("-" * 60)
    
    # ëŸ¬ì‹œì•„ì–´
    ru_total = sum(category_stats[category]["ru"].values())
    print(f"ëŸ¬ì‹œì•„ì–´ (ì´ {ru_total}íšŒ):")
    if ru_total > 0:
        ru_sorted = sorted(category_stats[category]["ru"].items(), key=lambda x: x[1], reverse=True)
        for marker, count in ru_sorted:
            if count > 0:
                percentage = (count / ru_total) * 100
                print(f"  {marker}: {count}íšŒ ({percentage:.1f}%)")
    else:
        print("  (í•´ë‹¹ í‘œí˜„ ì—†ìŒ)")
    
    # í•œêµ­ì–´
    ko_total = sum(category_stats[category]["ko"].values())
    print(f"\ní•œêµ­ì–´ (ì´ {ko_total}íšŒ):")
    if ko_total > 0:
        ko_sorted = sorted(category_stats[category]["ko"].items(), key=lambda x: x[1], reverse=True)
        for marker, count in ko_sorted:
            if count > 0:
                percentage = (count / ko_total) * 100
                print(f"  {marker}: {count}íšŒ ({percentage:.1f}%)")
    else:
        print("  (í•´ë‹¹ í‘œí˜„ ì—†ìŒ)")
    
    # ë¹„êµ
    ratio = ko_total / ru_total if ru_total > 0 else 0
    print(f"\nğŸ“ˆ ë¹„êµ: KO/RU = {ratio:.2f}")

# 10. ì „ì²´ í†µê³„ ìš”ì•½
print("\n" + "="*80)
print("ğŸ“‹ ì „ì²´ í†µê³„ ìš”ì•½")
print("="*80)

ru_grand_total = sum(ru_frequency.values())
ko_grand_total = sum(ko_frequency.values())
total_sentences = len(df)

print(f"ì´ ë¬¸ì¥ ìˆ˜: {total_sentences:,}ê°œ")
print(f"ëŸ¬ì‹œì•„ì–´ ë‹´í™” í‘œì§€ ì´ê³„: {ru_grand_total:,}íšŒ (í‰ê·  {ru_grand_total/total_sentences:.2f}ê°œ/ë¬¸ì¥)")
print(f"í•œêµ­ì–´ ë‹´í™” í‘œì§€ ì´ê³„: {ko_grand_total:,}íšŒ (í‰ê·  {ko_grand_total/total_sentences:.2f}ê°œ/ë¬¸ì¥)")
print(f"í•œêµ­ì–´/ëŸ¬ì‹œì•„ì–´ ë¹„ìœ¨: {ko_grand_total/ru_grand_total:.2f}")

# 11. ìƒìœ„ í‘œí˜„ ìˆœìœ„
print(f"\nğŸ“ˆ ìƒìœ„ ë‹´í™” í‘œì§€ (ë¹ˆë„ìˆœ)")
print("-" * 50)

print("ëŸ¬ì‹œì•„ì–´ TOP 10:")
ru_top = sorted([(k, v) for k, v in ru_frequency.items() if v > 0], key=lambda x: x[1], reverse=True)[:10]
for i, (marker, count) in enumerate(ru_top, 1):
    print(f"  {i:2d}. {marker}: {count:,}íšŒ")

print("\ní•œêµ­ì–´ TOP 10:")
ko_top = sorted([(k, v) for k, v in ko_frequency.items() if v > 0], key=lambda x: x[1], reverse=True)[:10]
for i, (marker, count) in enumerate(ko_top, 1):
    print(f"  {i:2d}. {marker}: {count:,}íšŒ")

# 12. ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬ëœ ê²°ê³¼ ìƒì„±
print("\nğŸ“Š ì •ë¦¬ëœ ê²°ê³¼ í…Œì´ë¸” ìƒì„± ì¤‘...")

# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
results_data = []

for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    # ëŸ¬ì‹œì•„ì–´ ë°ì´í„°
    for marker, count in category_stats[category]["ru"].items():
        if count > 0:
            results_data.append({
                "ë²”ì£¼": category,
                "ì–¸ì–´": "ëŸ¬ì‹œì•„ì–´", 
                "í‘œí˜„": marker,
                "ë¹ˆë„": count,
                "ë²”ì£¼ë‚´ë¹„ìœ¨": f"{(count/sum(category_stats[category]['ru'].values()))*100:.1f}%" if sum(category_stats[category]["ru"].values()) > 0 else "0%",
                "ì „ì²´ë¹„ìœ¨": f"{(count/total_sentences)*100:.2f}%"
            })
    
    # í•œêµ­ì–´ ë°ì´í„°
    for marker, count in category_stats[category]["ko"].items():
        if count > 0:
            results_data.append({
                "ë²”ì£¼": category,
                "ì–¸ì–´": "í•œêµ­ì–´",
                "í‘œí˜„": marker, 
                "ë¹ˆë„": count,
                "ë²”ì£¼ë‚´ë¹„ìœ¨": f"{(count/sum(category_stats[category]['ko'].values()))*100:.1f}%" if sum(category_stats[category]["ko"].values()) > 0 else "0%",
                "ì „ì²´ë¹„ìœ¨": f"{(count/total_sentences)*100:.2f}%"
            })

results_df = pd.DataFrame(results_data)

print("\nìµœì¢… ê²°ê³¼ í…Œì´ë¸”:")
print(results_df.to_string(index=False))

# CSV íŒŒì¼ë¡œ ì €ì¥
results_df.to_csv('discourse_markers_analysis_results.csv', index=False, encoding='utf-8')
print(f"\nâœ… ê²°ê³¼ê°€ 'discourse_markers_analysis_results.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 13. ë²”ì£¼ë³„ ìš”ì•½ í‘œ ìƒì„± (ìš”ì²­ëœ ì–‘ì‹)
print("\n" + "="*80)
print("ğŸ“‹ ë²”ì£¼ë³„ ìš”ì•½ í‘œ (ë…¼ë¬¸ìš©)")
print("="*80)

summary_data = []
total_sentences = len(df)

for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    ru_total = sum(category_stats[category]["ru"].values())
    ko_total = sum(category_stats[category]["ko"].values())
    
    # ë¬¸ì¥ ë¹„ìœ¨ ê³„ì‚° (í•´ë‹¹ ë²”ì£¼ê°€ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì¥ì˜ ë¹„ìœ¨)
    ru_sentence_ratio = (ru_total / total_sentences) * 100
    ko_sentence_ratio = (ko_total / total_sentences) * 100
    
    # ì°¨ì´ ê³„ì‚° (í•œêµ­ì–´ - ëŸ¬ì‹œì•„ì–´)
    difference = ko_sentence_ratio - ru_sentence_ratio
    
    summary_data.append({
        "ë²”ì£¼": category,
        "ëŸ¬ì‹œì•„ì–´": f"{total_sentences}ê°œ\n({ru_sentence_ratio:.2f}%)",
        "í•œêµ­ì–´": f"{total_sentences}ê°œ\n({ko_sentence_ratio:.2f}%)", 
        "ì°¨ì´": f"{difference:+.2f}%"
    })

summary_df = pd.DataFrame(summary_data)

print("\nğŸ“Š ë²”ì£¼ë³„ ë¶„í¬ ìš”ì•½í‘œ:")
print("-" * 60)
print(f"{'ë²”ì£¼':<12} {'ëŸ¬ì‹œì•„ì–´':<15} {'í•œêµ­ì–´':<15} {'ì°¨ì´':<10}")
print("-" * 60)

for _, row in summary_df.iterrows():
    ru_info = row['ëŸ¬ì‹œì•„ì–´'].replace('\n', ' ')
    ko_info = row['í•œêµ­ì–´'].replace('\n', ' ')
    print(f"{row['ë²”ì£¼']:<12} {ru_info:<15} {ko_info:<15} {row['ì°¨ì´']:<10}")

# 14. ë” ì •í™•í•œ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ê³„ì‚°
print("\n" + "="*80)
print("ğŸ“ˆ ì •í™•í•œ ë¬¸ì¥ ë‹¨ìœ„ ë¶„í¬ ë¶„ì„")
print("="*80)

# ê° ë¬¸ì¥ì—ì„œ ë‹´í™” í‘œì§€ê°€ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
def count_sentences_with_markers(df, patterns, language, category_markers):
    """ê° ë²”ì£¼ë³„ë¡œ ë‹´í™” í‘œì§€ê°€ í¬í•¨ëœ ë¬¸ì¥ ìˆ˜ ê³„ì‚°"""
    category_sentence_counts = defaultdict(int)
    
    for idx, row in df.iterrows():
        text = str(row[language]) if pd.notna(row[language]) else ""
        
        for category, markers in category_markers.items():
            lang_markers = markers.get(language, [])
            has_marker = False
            
            for marker in lang_markers:
                if marker in patterns[language]:
                    pattern = patterns[language][marker]
                    if re.search(pattern, text, re.IGNORECASE):
                        has_marker = True
                        break
            
            if has_marker:
                category_sentence_counts[category] += 1
    
    return category_sentence_counts

# ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„ ì‹¤í–‰
ru_sentence_counts = count_sentences_with_markers(df, patterns, 'ru', discourse_markers)
ko_sentence_counts = count_sentences_with_markers(df, patterns, 'ko', discourse_markers)

print("\nğŸ“Š ë‹´í™” í‘œì§€ê°€ í¬í•¨ëœ ë¬¸ì¥ ìˆ˜ (ë” ì •í™•í•œ ë¶„ì„):")
print("-" * 70)
print(f"{'ë²”ì£¼':<15} {'ëŸ¬ì‹œì•„ì–´':<20} {'í•œêµ­ì–´':<20} {'ì°¨ì´'}")
print("-" * 70)

final_summary = []

for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    ru_sentences = ru_sentence_counts[category]
    ko_sentences = ko_sentence_counts[category]
    
    ru_percentage = (ru_sentences / total_sentences) * 100
    ko_percentage = (ko_sentences / total_sentences) * 100
    
    difference = ko_percentage - ru_percentage
    
    print(f"{category:<15} {ru_sentences:>4}ê°œ ({ru_percentage:>5.2f}%) {ko_sentences:>4}ê°œ ({ko_percentage:>5.2f}%) {difference:>+6.2f}%")
    
    final_summary.append({
        "ë²”ì£¼": category,
        "ëŸ¬ì‹œì•„ì–´_ë¬¸ì¥ìˆ˜": ru_sentences,
        "ëŸ¬ì‹œì•„ì–´_ë¹„ìœ¨": f"{ru_percentage:.2f}%",
        "í•œêµ­ì–´_ë¬¸ì¥ìˆ˜": ko_sentences, 
        "í•œêµ­ì–´_ë¹„ìœ¨": f"{ko_percentage:.2f}%",
        "ì°¨ì´": f"{difference:+.2f}%"
    })

# 15. ìµœì¢… ìš”ì•½ í…Œì´ë¸” (ë…¼ë¬¸ìš© í˜•ì‹)
print("\n" + "="*80)
print("ğŸ“‹ ìµœì¢… ë…¼ë¬¸ìš© í‘œ í˜•ì‹")
print("="*80)

final_df = pd.DataFrame(final_summary)

print("\ní‘œ í˜•ì‹ (ë³µì‚¬í•´ì„œ ì‚¬ìš© ê°€ëŠ¥):")
print("="*60)
print("ë²”ì£¼\t\tëŸ¬ì‹œì•„ì–´\t\tí•œêµ­ì–´\t\tì°¨ì´")
print("-"*60)

for _, row in final_df.iterrows():
    category = row['ë²”ì£¼']
    ru_data = f"{total_sentences}ê°œ\n({row['ëŸ¬ì‹œì•„ì–´_ë¹„ìœ¨']})"
    ko_data = f"{total_sentences}ê°œ\n({row['í•œêµ­ì–´_ë¹„ìœ¨']})" 
    diff = row['ì°¨ì´']
    
    print(f"{category}\t{ru_data.replace(chr(10), ' ')}\t{ko_data.replace(chr(10), ' ')}\t{diff}")

# CSVë¡œ ìµœì¢… ìš”ì•½ ì €ì¥
final_df.to_csv('discourse_markers_summary_table.csv', index=False, encoding='utf-8')
print(f"\nâœ… ìµœì¢… ìš”ì•½í‘œê°€ 'discourse_markers_summary_table.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 16. ë“±ì¥ ë¹ˆë„ ê¸°ì¤€ ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ ë¹„êµí‘œ
print("\n" + "="*80)
print("ğŸ“Š ë“±ì¥ ë¹ˆë„ ê¸°ì¤€ ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ ë¹„êµí‘œ")
print("="*80)

frequency_comparison = []

for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    ru_total = sum(category_stats[category]["ru"].values())
    ko_total = sum(category_stats[category]["ko"].values())
    
    # ë¹„ìœ¨ ê³„ì‚° (ì „ì²´ ë‹´í™”í‘œì§€ ëŒ€ë¹„)
    ru_total_markers = sum(ru_frequency.values())
    ko_total_markers = sum(ko_frequency.values())
    
    ru_percentage = (ru_total / ru_total_markers) * 100 if ru_total_markers > 0 else 0
    ko_percentage = (ko_total / ko_total_markers) * 100 if ko_total_markers > 0 else 0
    
    # ì°¨ì´ ê³„ì‚°
    difference = ko_total - ru_total
    ratio = ko_total / ru_total if ru_total > 0 else float('inf') if ko_total > 0 else 0
    
    frequency_comparison.append({
        "ë²”ì£¼": category,
        "ëŸ¬ì‹œì•„ì–´_ë¹ˆë„": ru_total,
        "ëŸ¬ì‹œì•„ì–´_ë¹„ìœ¨": f"{ru_percentage:.1f}%",
        "í•œêµ­ì–´_ë¹ˆë„": ko_total,
        "í•œêµ­ì–´_ë¹„ìœ¨": f"{ko_percentage:.1f}%",
        "ì°¨ì´": difference,
        "í•œêµ­ì–´/ëŸ¬ì‹œì•„ì–´": f"{ratio:.2f}" if ratio != float('inf') else "âˆ"
    })

freq_comparison_df = pd.DataFrame(frequency_comparison)

print("\nğŸ“‹ ë“±ì¥ ë¹ˆë„ ê¸°ì¤€ ë¹„êµí‘œ:")
print("-" * 90)
print(f"{'ë²”ì£¼':<12} {'ëŸ¬ì‹œì•„ì–´':<15} {'í•œêµ­ì–´':<15} {'ì°¨ì´':<8} {'ë¹„ìœ¨(KO/RU)':<12}")
print("-" * 90)

for _, row in freq_comparison_df.iterrows():
    ru_info = f"{row['ëŸ¬ì‹œì•„ì–´_ë¹ˆë„']:,}íšŒ ({row['ëŸ¬ì‹œì•„ì–´_ë¹„ìœ¨']})"
    ko_info = f"{row['í•œêµ­ì–´_ë¹ˆë„']:,}íšŒ ({row['í•œêµ­ì–´_ë¹„ìœ¨']})"
    diff = f"{row['ì°¨ì´']:+,}íšŒ"
    ratio = row['í•œêµ­ì–´/ëŸ¬ì‹œì•„ì–´']
    
    print(f"{row['ë²”ì£¼']:<12} {ru_info:<15} {ko_info:<15} {diff:<8} {ratio:<12}")

# 17. ëŸ¬ì‹œì•„ì–´ ë²”ì£¼ë³„ ìˆœìœ„í‘œ
print("\n" + "="*80)
print("ğŸ‡·ğŸ‡º ëŸ¬ì‹œì•„ì–´ ë‹´í™” í‘œì§€ ë²”ì£¼ë³„ ìˆœìœ„")
print("="*80)

ru_category_ranking = []
for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    total = sum(category_stats[category]["ru"].values())
    ru_category_ranking.append((category, total))

ru_category_ranking.sort(key=lambda x: x[1], reverse=True)

print("\nğŸ“Š ëŸ¬ì‹œì•„ì–´ ë²”ì£¼ë³„ ìˆœìœ„:")
print("-" * 50)
print(f"{'ìˆœìœ„':<4} {'ë²”ì£¼':<15} {'ë¹ˆë„':<10} {'ë¹„ìœ¨'}")
print("-" * 50)

ru_total_all = sum(ru_frequency.values())
for rank, (category, frequency) in enumerate(ru_category_ranking, 1):
    percentage = (frequency / ru_total_all) * 100
    print(f"{rank:<4} {category:<15} {frequency:,}íšŒ{'':<5} {percentage:.1f}%")

# 18. í•œêµ­ì–´ ë²”ì£¼ë³„ ìˆœìœ„í‘œ  
print("\n" + "="*80)
print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë‹´í™” í‘œì§€ ë²”ì£¼ë³„ ìˆœìœ„")
print("="*80)

ko_category_ranking = []
for category in ["ì ‘ì† í‘œì§€", "ì¡°ê±´/ëŒ€ë¦½ í‘œì§€", "ê·¼ê±°/ì§€ì‹œ í‘œì§€", "ê·œë²” ì–‘ìƒ í‘œì§€", "ì°¸ì¡° í‘œì§€"]:
    total = sum(category_stats[category]["ko"].values())
    ko_category_ranking.append((category, total))

ko_category_ranking.sort(key=lambda x: x[1], reverse=True)

print("\nğŸ“Š í•œêµ­ì–´ ë²”ì£¼ë³„ ìˆœìœ„:")
print("-" * 50)
print(f"{'ìˆœìœ„':<4} {'ë²”ì£¼':<15} {'ë¹ˆë„':<10} {'ë¹„ìœ¨'}")
print("-" * 50)

ko_total_all = sum(ko_frequency.values())
for rank, (category, frequency) in enumerate(ko_category_ranking, 1):
    percentage = (frequency / ko_total_all) * 100
    print(f"{rank:<4} {category:<15} {frequency:,}íšŒ{'':<5} {percentage:.1f}%")

# 19. ë²”ì£¼ë³„ ìˆœìœ„ ë¹„êµ ìš”ì•½
print("\n" + "="*80)
print("ğŸ“ˆ ëŸ¬ì‹œì•„ì–´ vs í•œêµ­ì–´ ë²”ì£¼ë³„ ìˆœìœ„ ë¹„êµ")
print("="*80)

print("\nğŸ“Š ìˆœìœ„ ë¹„êµí‘œ:")
print("-" * 70)
print(f"{'ìˆœìœ„':<4} {'ëŸ¬ì‹œì•„ì–´':<20} {'ë¹ˆë„':<8} {'í•œêµ­ì–´':<20} {'ë¹ˆë„'}")
print("-" * 70)

max_ranks = max(len(ru_category_ranking), len(ko_category_ranking))
for i in range(max_ranks):
    ru_info = f"{ru_category_ranking[i][0]} ({ru_category_ranking[i][1]:,}íšŒ)" if i < len(ru_category_ranking) else "-"
    ko_info = f"{ko_category_ranking[i][0]} ({ko_category_ranking[i][1]:,}íšŒ)" if i < len(ko_category_ranking) else "-"
    
    ru_category = ru_category_ranking[i][0] if i < len(ru_category_ranking) else ""
    ru_freq = f"{ru_category_ranking[i][1]:,}" if i < len(ru_category_ranking) else ""
    ko_category = ko_category_ranking[i][0] if i < len(ko_category_ranking) else ""
    ko_freq = f"{ko_category_ranking[i][1]:,}" if i < len(ko_category_ranking) else ""
    
    print(f"{i+1:<4} {ru_category:<20} {ru_freq:<8} {ko_category:<20} {ko_freq}")

# 20. ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
# ë¹ˆë„ ë¹„êµí‘œ
freq_comparison_df.to_csv('frequency_comparison_table.csv', index=False, encoding='utf-8')

# ëŸ¬ì‹œì•„ì–´ ìˆœìœ„í‘œ
ru_ranking_df = pd.DataFrame([(rank, cat, freq, f"{(freq/ru_total_all)*100:.1f}%") 
                             for rank, (cat, freq) in enumerate(ru_category_ranking, 1)],
                            columns=['ìˆœìœ„', 'ë²”ì£¼', 'ë¹ˆë„', 'ë¹„ìœ¨'])
ru_ranking_df.to_csv('russian_category_ranking.csv', index=False, encoding='utf-8')

# í•œêµ­ì–´ ìˆœìœ„í‘œ  
ko_ranking_df = pd.DataFrame([(rank, cat, freq, f"{(freq/ko_total_all)*100:.1f}%") 
                             for rank, (cat, freq) in enumerate(ko_category_ranking, 1)],
                            columns=['ìˆœìœ„', 'ë²”ì£¼', 'ë¹ˆë„', 'ë¹„ìœ¨'])
ko_ranking_df.to_csv('korean_category_ranking.csv', index=False, encoding='utf-8')

print(f"\nâœ… ì¶”ê°€ ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
print("  - frequency_comparison_table.csv (ë¹ˆë„ ë¹„êµí‘œ)")
print("  - russian_category_ranking.csv (ëŸ¬ì‹œì•„ì–´ ìˆœìœ„í‘œ)")
print("  - korean_category_ranking.csv (í•œêµ­ì–´ ìˆœìœ„í‘œ)")

print("\nğŸ‰ ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
